\chapter{An Extended Synthesis Calculus}
\label{chapter:extended}

So far, we have considered a language with a several basic types, but which
falls short of the full expressive power of Granule. In this chapter, we
consider a target language which is significantly more expressive than what we
have seen thus far, constituting a fully-fledged functional programming
language.

The above features could all have been added to the calculi from
Chapter~\ref{chapter:core}, however, we take the inclusion of these new language
features as an opportunity to also explore synthesis in a fully graded type
system. As mentioned in~\ref{chapter:background}, the fully-graded linear-lambda
calculus is one of the two dominant flavours of quantitative type system. This
approach is common amongst implementations of quantitative type systems, such
as Idris 2, the Linear Types language extension to GHC, and the
\emph{GradedBase} language extension of Granule. 

We begin by extending the calculus of Section~\ref{sec:graded-base}, adding the
synthesis of recursion, polymorphic user-defined algebraic data types, as well
as the synthesis of recursive function definitions from polymorphic type
schemes. Section~\ref{section:graded-base-typing} provides a full formal description 
of our target language.

We then provide a program synthesis calculus with an additive resource
management scheme for this language in
Section~\ref{section:graded-base-synthesis}, describing the rules in turn,
introducing some additional features such as the ability to specify input-output
examples for a desired synthesis problem (Section~\ref{sec:examples}), and
additional post-synthesis refactoring
procedures(Section~\ref{sec:graded-base-refactoring}). We then apply focusing to
this calculus in Section~\ref{section:graded-base-focusing}, as we did in
Chapter~\ref{chapter:core}, using this focused form as the basis of the
implementation of our synthesis tool.

The synthesis tool is evaluated We evaluate our implementation on a set of 46
benchmarks (Section~\ref{section:graded-base-evaluation}), including several non-trivial
programs which use algebraic data types and recursion.

In Section~\ref{sec:linear-haskell}, to demonstrate the practicality and
versatility of our approach, we apply our algorithm to synthesising programs in
Haskell from type signatures that use GHC's \emph{linear types} extension.


\section{A Fully Graded Target Language}
\label{section:graded-base-typing}

We now formally define our target language, extending the fully graded
$\lambda$-calculus of Chapter~\ref{chapter:background}. Our language comprises
the $\lambda$-calculus extended with grades and a graded necessity modality,
arbitrary user-defined recursive algebraic data types (ADTs), as well as rank-1
polymorphism. The syntax of types is given by:
\begin{align*}
    \hspace{-0.9em}[[ A ]] , [[ B ]] & ::=
           [[ A ^ r -> B ]]
      \mid K
      \mid [[ A B ]]
      \mid [[ [] r A ]]
      \mid \mu X . [[ A ]]
      \mid X
      \mid \alpha
    {\small{\tag{\textit{types}}}}
\end{align*}
\begin{align*}
    \hspace{-0.9em} K & ::=
           [[ Unit ]]
      \mid [[ Prod ]]
      \mid [[ Coprod ]]
    {\small{\tag{\textit{type constructors}}}}
\end{align*}
\begin{align*}
    \hspace{-0.9em} \tau & ::=
           [[ Forall alpha : k . A  ]]
    {\small{\tag{\textit{type schemes}}}}
\end{align*}
Recursive types $\mu X . A$ are equi-recursive (although we also provide
explicit typing rules) with type recursion variables $X$. Data constructors and
other top-level definitions are typed by type schemes $\tau$ (rank-1 polymorphic
types), which bind a set of kind-annotated universally quantified type variables
$\overline{\alpha : \kappa}$ à la ML~\citep{milner1978theory}. Thus,
types may contain type variables $[[ a ]]$. Kinds $\kappa$ are standard, given
by Figure~\ref{figure:kinding}.

The syntax of terms is given by:

\begin{align*}
        \hspace{-0.8em} [[ t ]] ::= \;
               & [[ x ]]
          \mid [[ \x ^ c . t ]]
          \mid [[ t1 t2 ]]
          \mid [[ [t] ]]
          \mid [[ Con t1 ... tn ]]
          \mid [[ case t of p1 -> t1 ; * ; pn -> tn  ]]
        {\small{\tag{\textit{terms} }}}
\end{align*}
\begin{align*}
        \hspace{-0.8em} [[ p ]] ::= \;
               & [[ x ]]
          \mid [[ _ ]]
          \mid [[ [p] ]]
          \mid [[ Con p1 ... pn ]]
        {\small{\tag{\textit{patterns}}}}
\end{align*}
Terms consist of a graded $\lambda$-calculus, a \textit{promotion} construct
 $[t]$ which introduces a graded modality explicitly, as well as data
 constructor introduction ($[[ Con t1 ... tn ]]$) and elimination via
 $\textbf{case}$ expressions with patterns, which are defined via the syntax of
 patterns $[[ p ]]$.

Typing judgements have the form $[[  Sig ; G |- t : A ]]$ assigning a type $[[ A
]]$ to a term $ [[ t ]]$ under type variables $[[ Sig ]]$ and variable context
$[[ G ]]$, given by:

\begin{equation*}
  [[ D ]], [[ G ]] ::= \emptyset
  \mid [[ G , x : [ A ] r ]]
\tag{\textit{contexts}}
\end{equation*}
%
That is, a context may be empty $\emptyset$ or extended with a \textit{graded}
assumption $ [[ x : [A] r ]]$. Graded assumptions must be used in a way which
adheres to the constraints of the grade $[[ r ]]$. Structural exchange is
permitted, allowing a context to be arbitrarily reordered. A global context $[[
Defs ]]$ parametrises the system, containing top-level definitions and data
constructors annotated with type schemes. A context of kind annotated type
variables $[[ Sig ]]$ is used for kinding and when instantiating a type scheme
from $[[ Defs ]]$. 

Given a typing judgment $[[  Sig ; G |- t : A ]]$ we say that $t$ is both
\emph{well typed} and \emph{well resourced} to highlight the role of grading in
accounting for resource use via the semiring information. Another judgment types
top-level terms (definitions) with polymorphic type schemes:
\begin{align*}
\tyTopP
\end{align*}
This rule takes the type scheme and adds its universally quantified type
variables to $[[ Sig ]]$, where they can be used subsequently in the typing
rules. The rule's premise then types the body at $A$, using the typing rules for
terms of Figure~\ref{fig:typing-graded-poly}, whose rules help explain the
meaning of the syntax with reference to their static semantics.

\begin{figure}[H]
    \begin{align*}
      {{
    \hspace{0em}\begin{array}{c}
        \kVar 
        \;\;\;
        \kBox 
        \\[1.25em]
        \kArrow
        \\[1.25em]
        \kApp 
        \\[1.25em]
        \kUnit
        \;\;\;
        \kProd 
        \\[1.25em]
        \kSum
        \\[1.25em]
        \kMuR
        \;\;\;
        \kMuL
    \end{array}
      }}
    \end{align*}
    \caption{Kinding rules for the fully graded typing calculus}
    \label{figure:kinding}
\end{figure}

\begin{figure}[t]
    \begin{align*}
    {\footnotesize{
    \hspace{-2.5em}
    \begin{array}{c}
    \tyVarP
    \\[1.25em]
    \tyDefP
        \\[1.25em]
    \tyAbsP
    \;\;\;
    \tyAppP
        \\[1.25em]
    \tyPrP
    \;\;\;
    \tyApproxP
        \\[1.25em]
    \tyConP
        \\[1.25em]
    \tyCaseP
        \\[1.25em]
    \tyMuRP
    \;\;\;
    \tyMuLP
    \end{array}
    }}
    \end{align*}
    \vspace{-1em}
    \caption{Typing rules for the fully graded polymorphic calculus}
    \label{fig:typing-graded-poly}
    \vspace{-0.5em}
\end{figure}
Top-level definitions are typed by the \textsc{Def} rule. The definition $x$
must be present in the global definition context $[[ Defs ]]$, with the type
scheme $[[  Forall alpha : k . A' ]]$. The type $[[ A ]]$ results from
instantiating all of the universal variables to types via the judgment $[[ Sig
|- inst A A' ]]$ in a standard way as in Algorithm W~\citep{milner1978theory}.

The graded $\lambda$-calculus fragment of our language remains mostly the same 
as in Section~\ref{sec:graded-base}. However, the \textsc{Var} rule also checks 
the kind of the assumption $x$'s type in the premise.  

Recursion is typed via the $\mu_1$ and $\mu_2$ rules, in a standard
way.

Introduction and elimination of data constructors is given by
the \textsc{Con} and \textsc{Case} rules respectively,
with \textsc{Case} also handling graded modality elimination via
pattern matching. For \textsc{Con}, we may type a data constructor
$[[C]]$ of some data type $[[ K {A Many} ]]$ (with zero or more type
parameters represented by $[[ {A Many} ]]$) if it is present in the global
context of data constructors $D$. Data constructors are closed
requiring our context $[[ G ]]$ to have zero-use grades, thus we scale
$[[G]]$ by $0$. Elimination of data constructors take place via
pattern matching over a constructor. Patterns $[[p]]$ are typed by the
judgement $[[ r |- p : A |> D ]]$ which states that a pattern $[[p]]$
has type $[[A]]$ and produces a context of typed binders $[[D]]$. The
grade $[[r]]$ to the left of the turnstile represents the grade
information arising from usage in the context generated by this
pattern match. The pattern typing rules are given by
Figure~\ref{fig:pat-typing}.

\begin{figure}[t]
    \begin{align*}
      {\footnotesize{
    \hspace{-3em}\begin{array}{c}
    \patWildP
    \\[1.25em]
    \patVarP
    \;\;\;
    \patBoxP
    \\[1.25em]
    \patConP
    \end{array}
      }}
    \end{align*}
    \vspace{-1.25em}
      \caption{Pattern typing rules of for the fully graded typing calculus}
    \label{fig:pat-typing}
\end{figure}

Variable patterns are typed by \textsc{PVar}, which simply produces a singleton
context containing an assumption $[[ x : [A] r]]$ from the variable pattern with
any grade $[[ r ]]$. A wildcard pattern $\_$, typed by the \textsc{PWild} rule,
is only permissible with grades that allow for weakening, i.e., where $0
\sqsubseteq r$. Pattern matching over data constructors is handled by the
\textsc{PCon} rule. A data constructor may have up to zero or more sub-patterns
($[[ p1 ]] ... [[ pn ]]$), each of which is typed under the grade $[[ qi ]]
\cdot [[ r ]]$ (where $[[ qi ]]$ is the grade of corresponding argument type for
the constructor, as defined in $D$). Additionally, we have the constraint
$[[{PolyConSimple {K {A Many}} r}]]$ which witnesses the fact that if there is
more than one data constructor for the data type (written $|[[ K {A Many} ]]| >
1$), then $[[ r ]]$ must approximate 1 because pattern matching on a data
constructor incurs some usage since it reveals information about that
constructor.\footnote{A discussion of this additional constraint on grades for
case expressions is given by \citet{DBLP:journals/corr/abs-2112-14966} comparing
how this manifests in various approaches.} By contrast, pattern matching on a
type with only one constructor cannot convey any information by itself and so no
usage requirement is imposed. Finally, elimination of a graded modality (often
called \textit{unboxing}) takes place via the \textsc{PBox} rule, with syntax
$[[ [p] ]]$. Like \textsc{PCon}, this rule propagates the grade information of
the box pattern's type $[[s]]$ to the enclosed sub-pattern $[[ p ]]$, yielding a
context with the grades $[[r * s]]$. One may observe that \textsc{PBox} (and by
extension \textsc{Pr}) could be considered as special cases of \textsc{PCon}
(and \textsc{Con} respectively), if we were to treat our promotion construct as
a data constructor with the type $[[ A ^ r -> {[] r A} ]]$. We find it helpful
to keep explicit modality introduction and elimination distinct from
constructors, however, particularly with regard to synthesis.

\subsection{Metatheory}
Lastly we note that the fully graded system also enjoys admissibility of
substitution~\citep{DBLP:journals/pacmpl/AbelB20}
which is critical in type preservation proofs,
and is needed in our proof of soundness for synthesis:
%
\begin{restatable}[Admissibility of substitution]{lemma}{subst}
\label{lemma:substitution}
Let $[[ D |- t' : A]]$, then:
If $[[ {G, x : [A] r} , G' |- t : B]]$
then $[[ G + (r * D) + G' |- [ t' / x ] t : B ]]$
\end{restatable}


\section{A Fully Graded Synthesis Calculus}
\label{section:graded-base-synthesis}

Having defined the target language, we define our synthesis calculus, which uses
the \emph{additive} approach to resource management (see
Section~\ref{subsec:additive}), with judgements:
%
\begin{align*}
[[ Sig; G |- A =>+ t ; D ]]
\end{align*}
%
That is, given an input context $[[ G ]]$, for goal type $[[ A ]]$ we can
synthesise the term $[[ t ]]$ with the output context $[[ D ]]$ describing how
variables were used in $[[ t ]]$. As with the typing rules, top-level
definitions and data constructors in scope are contained in a set $[[ Defs ]]$,
which parametrises the system. $[[ Sig ]]$ is a context of kind-annotated type
variables, which we elide in rules where it is passed inductively to the
premise(s). The graded context $[[ D ]]$ need not use all the variables in $[[ G
]]$, nor with exactly the same grades. Instead, the relationship between
synthesis and typing is given by the central soundness result, which we state
up-front: % (the appendix provides the proof):
%(Appendix~\ref{sec:soundness-proofs} provides the proof):

\begin{restatable}[Soundness of synthesis]{theorem}{synthSound}
\label{lemma:synthSound}
Given a particular pre-ordered semiring $\mathcal{R}$ parametrising the calculi,
then:
\begin{enumerate}
\item For all contexts $[[ G ]]$ and $[[ D ]]$, types $[[ A ]]$, terms $[[ t ]]$:
\begin{align*}
[[ Sig; G |- A =>+ t ; D ]] \quad \implies \quad [[ Sig; D |- t : A ]]
\end{align*}
i.e. $[[ t ]]$ has type $[[ A ]]$
under context $[[ D ]]$ whose grades capture variable use in $[[ t ]]$.
\item At the top-level,
for all type schemes $[[ Forall alpha : k . A ]]$ and terms $[[ t ]]$ then:
%
\begin{align*}
[[ . ; . |- Forall alpha : k . A =>+ t ; . ]]
\quad \implies \quad [[  . ; . |- t : Forall alpha : k . A ]]
\end{align*}
%
\end{enumerate}
\end{restatable}

\begin{figure}
    \begin{align*}
      {\footnotesize{
    \hspace{-3em}\begin{array}{c}
      \synDefP
      \\[1.25em]
      \synTopP
      \;\;\;
      \synVarP
      \\[1.25em]
      \synAbsP
      \\[1.25em]
      \synAppP
      \\[1.25em]
      \synConP
      \\[1.25em]
      \synCaseP
      \\[1.25em]
      \synBoxP
      \\[1.25em]
      \synUnboxP
      \\[1.25em]
      \synMuRP
      \;\;\;\;
      \synMuLP
        \end{array}
      }}
      \end{align*}
    \caption{Collected rules of the fully graded synthesis calculus}
    \end{figure}
%
The first part of soundness on its own does not guarantee that a synthesised
program $t$ is \emph{well resourced}, i.e., the grades in $[[ D ]]$ may not be
approximated by the grades in $[[ G ]]$. For example, a valid judgement (whose
more general rule is seen shortly) under semiring $\mathbb{N}_\equiv$ is:
%
\begin{align*}
[[ x : [A] 2 |- A =>+ x ; x : [A] 1 ]]
\end{align*}
%
i.e., for goal $A$, if $x$ has type $A$ in the context then we synthesis $x$ as
the result program, regardless of the grades. A synthesis judgement such as this
may be part of a larger derivation in which the grades eventually match, i.e.,
this judgement forms part of a larger derivation which has a further
sub-derivation in which $x$ is used again and thus the total usage for $x$ is
eventually $2$ as prescribed by the input context. However, at the level of an
individual judgement we do not guarantee that the synthesised term is
well-resourced. A reasonable \emph{pruning condition} that could be used to
assess whether any synthesis judgement is \emph{potentially} well-resourced is
$\exists [[ D' ]] . [[ (D + D') <<= G ]]$, i.e., there is some additional usage
$[[ D' ]]$ (that might come from further on in the synthesis process) that
`fills the gap' in resource use to produce $[[ D + D' ]]$ which is
overapproximated by $[[ G ]]$. In this example, $[[ D' ]] = [[ x : [A] 1 ]]$
would satisfy this constraint, explaining that there is some further possible
single usage which will satisfy the incoming grade. However,
Chapter~\ref{chapter:core} showed that excessive pruning at every step becomes
too costly in a general setting. Instead, we apply such pruning more
judiciously, only requiring that variable use is well-resourced at the point of
synthesising binders. Therefore synthesised closed terms are always
well-resourced (second part of the soundness theorem).

Section~\ref{proofs:graded-base-soundness} of Appendix~\ref{appendix:proofs} provides the soundness
proof, which in part resembles a translation from sequent calculus to natural
deduction, but also with the management of grades between synthesis and type
checking.

For open terms, the implementation checks that from a user-given top-level goal
$A$ for which $[[ G |- A => t ; D ]]$ is derivable then $t$ is only provided as
a valid (well-typed and well-resourced) result if $[[ D <<= G ]]$.

We next present the synthesis calculus in stages. Each type former of the core
calculus (with the exception of type variables) has two corresponding synthesis
rules: a right rule for introduction (labelled $\textsc{R}$) and a left rule for
elimination (labelled $\textsc{L}$). We frequently apply the algorithmic reading
of the judgements, where meta-level terms to the left of $\Rightarrow$ are
inputs (i.e., context $[[ G ]]$ and goal type $[[ A ]]$) and terms to the right
of $\Rightarrow$ are outputs (i.e., the synthesised term $[[ t ]]$ and the usage
context $[[ D ]]$).
%Section~\ref{subsection:rules} focuses primarily on a
%simply-typed core of synthesis, explaining how each synthesis
%rule addresses the issue of resource management, and how usage
%information is conveyed from a rule's input to its output.
%Section~\ref{sec:recursion} explains
%the approach to synthesising recursive programs (and handling recursive data types).
%Section~\ref{sec:polymorphism} briefly explains the handling of polymorphism.
%
% \iffalse
The synthesis calculus is non-deterministic, i.e., for any $[[ G ]]$
and $[[ A ]]$ there may be many possible $[[ t ]]$ and $[[ D ]]$ such
that $[[ G |- A =>+ t ; D ]]$. 

\subsection{Core Synthesis Rules}
\label{subsection:rules}
\subsubsection{Top-level}
We begin with the \textsc{TopLevel} rule, which is
for a judgment form with a type scheme goal instead of just a
type, providing the entry-point to synthesis:
\begin{align*}
  \synTopP
\end{align*}
This rule takes the universally quantified type variables $\overline{\alpha : \kappa}$
from the type scheme and adds them to the type variable context $\Sigma$;
type variables are only equal to themselves. This rule corresponds
to the generalisation step of typing polymorphic definitions~\citep{milner1978theory}.

\subsubsection{Variables}
For any goal type $A$, if there is a variable in the context matching this type
then it can be synthesised for the goal, given by the terminal rule:
%
\begin{align*}
  \synVarP
\end{align*}
%
Said another way, to synthesise the use of a variable $[[ x ]]$, we require that $[[ x ]]$ be
present in the input context $[[ G ]]$. The output context here then explains
that only variable $x$ is used: it consists of the
entirety of the input context $[[ G ]]$ scaled by grade $0$ (using
Definition~\ref{def:scalar}), extended with $[[x : [A] 1]]$, i.e. a single usage
of $[[ x ]]$ as denoted by the $1$ element of the semiring.
Maintaining this zeroed $[[ G ]]$ in the output context simplifies
subsequent rules by avoiding excessive context membership checks.

The $\textsc{Var}$ rule permits the synthesis of terms which may not
be well-resourced, e.g., if $r = 0$, the rule still synthesises a use of
$x$. This is locally ill-resourced, but is acceptable at the global
level as we check that an assumption has been used correctly in the rule where the assumption is bound. This does leads us to consider some branches of synthesis
that are guaranteed to fail: at the point of synthesising a usage of a
variable in the additive scheme, isolated from information about how
else the variable is used, there is no way of knowing if such a usage
will be permissible in the final synthesised program. However, it also
reduces the amount of intermediate theorems that need solving, which
can significantly effect performance as shown
in Chapter~\ref{chapter:core}, especially since the variable
rule is applied very frequently.

\subsubsection{Functions}

Synthesis of programs from function types is handled by the \GRANULEdruleAbsName and
\GRANULEdruleAppName rules, which synthesise abstraction and application terms,
respectively. An abstraction is synthesised like so:
\begin{align*}
    \synAbs
\end{align*}
%
Reading bottom up, to synthesise a term of type
$[[ A ^ q -> B ]]$ in context $[[ G ]]$ we first
extend the context
with a fresh variable assumption $[[ x : [A] q ]]$ and synthesise a term of type $[[ B ]]$ that will ultimately become the body
of the function. The type $[[ A ^ q -> B ]]$ conveys that $[[ A ]]$ must be
used according to $[[ q ]]$ in our term for $[[ B ]]$. The fresh variable
$[[ x ]]$  is passed to the premise of the rule using
the grade of the binder: $[[ q ]]$. The $[[ x ]]$ must then be used to synthesise a term
$[[ t ]]$ with $[[ q ]]$ usage. In the premise, after synthesising $[[ t ]]$ we obtain an output context
$[[ D, x : [A] r ]]$. As mentioned, the $\textsc{Var}$ rule ensures
that $[[ x ]]$ is present in this context, even if it was not used in the
synthesis of $[[ t ]]$ (e.g., $[[ r ]] = 0$).
The rule ensures the usage of bound term ($r$) in $[[t]]$ does not violate the
input grade $q$ via the requirement that $[[ r ]] \sqsubseteq [[ q ]]$ i.e. that $[[ r ]]$
\textit{approximates} $[[ q ]]$. If met, $[[ D ]]$ becomes the output context of the rule's conclusion.

The counterpart to abstraction synthesises an
application from the occurrence of a function in the context (a left rule):
\begin{align*}
  \hspace{-5em}{\footnotesize{
    \synApp
  }}
\end{align*}
%
Reading bottom up again, the input context contains an assumption with a function type
$[[ x1 : [A ^ q -> B] r1 ]]$. We may attempt to use this assumption in the synthesis of a
term with the goal type $[[ C ]]$, by applying some argument to it. We do this
by synthesising the argument from the input type of the function $[[ A ]]$, and
then binding the result of this application as an assumption of type $[[ B ]]$ in the
synthesis of $[[ C ]]$. This is decomposed into two steps corresponding to the two
premises (though in the implementation the first premise is considered first):
\begin{enumerate}
        \item The first premise synthesises a term $[[ t1 ]]$ from the goal type
        $[[ C ]]$ under the assumption that the function $[[ x1 ]]$ has been
        applied and its result is bound to
        $[[ x2 ]]$. This placeholder assumption is bound with the same grade as
        $[[ x1 ]]$.
        \item The second premise synthesises an argument $[[ t2 ]]$
        of type $[[ A ]]$ for the function $[[ x1 ]]$.
        In the implementation, this synthesis step occurs only after
        a term $[[ t1 ]]$ is found for the goal $[[ C ]]$ as a heuristic
        to avoid possibly unnecessary work if no term can be synthesised for
        $[[ C ]]$.
\end{enumerate}
%
In the conclusion of the rule, a term is synthesised
which substitutes in $[[ t1 ]]$ the result placeholder variable $[[ x2 ]]$ for the application
$[[ x1 t2 ]]$.

The first premise yields an output context
$[[ D1, x1 : [ A ^ q -> B ] s1, x2 : [B] s2 ]]$.
The output context of the conclusion is obtained by taking the context addition of
$[[ D1 ]]$ and $[[ s2 * {q * D2} ]]$. The output context $[[ D2 ]]$ is first scaled by
$[[ q ]]$ since $[[ t2 ]]$ is used according to $[[ q ]]$ when applied to
$[[ x1 ]]$ (as per the type of $[[ x1 ]]$). We then scale this again by $[[ s2 ]]$
which represents the usage of the entire application $[[ x1 t2 ]]$ inside
$[[ t1 ]]$.

The output grade of $[[ x1 ]]$ follows a similar pattern
since this rule permits the re-use of
$[[ x1 ]]$ inside both premises of the application (which
differs from our treatment of synthesis in a linear setting).
As $[[ x1 ]]$'s input grade $[[ r1 ]]$ may permit multiple uses both inside the
synthesis of the application argument $[[ t2 ]]$ and in $[[ t1 ]]$ itself, the
total usage of $[[ t1 ]]$ across both premises must be calculated. In the first
premise $[[ x1 ]]$ is used according to $[[ s1 ]]$, and in the second according
to $[[ s3 ]]$. As with $[[ D2 ]]$, we take the semiring multiplication of $[[ s3 ]]$ and $[[ q ]]$ and then
multiply this by $[[ s2 ]]$ to yield the final usage of $[[ x1 ]]$ in $[[ t2 ]]$.
We then add this to $[[ s2 + s1 ]]$ to yield the total usage of $[[ x1 ]]$ in
$[[ t1 ]]$.

\subsubsection{Using polymorphic definitions}

Programs can be synthesised from a polymorphic type scheme (the
previously shown \textsc{TopLevel} rule), treating
universally-quantified type variables at the top-level of our goal type
as logical atoms which cannot be unified with and are only equal to
themselves. The \textsc{Def} rule synthesises a \emph{use}
of a top-level polymorphic function via instantiation:
\begin{align*}
  \synDefP
\end{align*}
%
For example, in the following we have a polymorphic
function \granin{flip} that we want to use to synthesise a monomorphic function:
%
\begin{granule}
flip : forall c d  . (c, d) %1 -> (d, c)
flip (x, y) = (y, x)
f : (Int, Int) %1 -> (Int, Int)
f x = ? -- synthesis to flip x trivially
\end{granule}
%
To synthesise the term \granin{flip x}, the type scheme of \granin{flip} is
instantiated via \textsc{Def} with
$\emptyset \vdash (\mathit{Int} \otimes \mathit{Int})^1 \rightarrow (\mathit{Int} \otimes \mathit{Int})
= \text{inst}(\forall c : \text{Type}, d : \text{Type} . (c \otimes d)^1 \rightarrow (d \otimes c))$.

\subsubsection{Graded modalities}

Graded modalities are introduced and eliminated explicitly through the
\GRANULEdruleBoxName and \GRANULEdruleUnboxName rules, respectively. In the
\GRANULEdruleBoxName{} rule, we synthesise a promotion $[[ [ t ] ]]$ for some graded
modal goal type $[[ [] r A ]]$:
\begin{align*}
  \synBox
\end{align*}
In the premise, we synthesise from $[[ A ]]$, yielding the sub-term $[[ t ]]$ and
an output context $[[ D ]]$. In the conclusion, $[[ D ]]$ is scaled by the grade
of the goal type $[[ r ]]$: as $[[ [t] ]]$ must use $[[ t ]]$ as $[[ r ]]$
requires.

Grade elimination (\textit{unboxing}) takes place via
pattern matching in a \textbf{case} statement:
\begin{align*}
  \synUnbox
\end{align*}
To eliminate the assumption $[[ x ]]$ of graded modal type $[[ [] q
A ]]$, we bind a fresh assumption in the synthesis of the premise: $[[ y : [A]
{r * q} ]]$. This assumption is graded with $[[ {r * q} ]]$: the grade from the
assumption's type multiplied by the grade of the assumption itself. As with
previous elimination rules, $[[ x ]]$ is rebound in the rule's premise. A
term $[[ t ]]$ is then synthesised resulting in the output context $[[ {D, y :
[A] s1}, x : [ [] q A ] {s2} ]]$, where $[[ s1 ]]$ and $[[ s2 ]]$ describe how
$[[ y ]]$ and $[[ x ]]$ were used in $[[ t ]]$. The second premise ensures that
the usage of $[[ y ]]$ is well-resourced. The grade $[[ s3 ]]$ represents how
much the usage of $[[ y ]]$ inside $[[ t]]$ contributes to the overall usage of
$ [[ x]]$. The constraint $[[ s1 ]] \sqsubseteq [[ s3 * q ]]$ conveys the fact
that $[[ q ]]$ uses of $[[y]]$ constitutes a single use of $[[ x ]]$, with the constraint
$[[ s3 * q ]] \sqsubseteq [[r * q]]$ ensuring that the overall usage does not exceed the binding grade. For the
output context of the conclusion, we simply remove the bound $[[y]]$ from $[[ D
]]$ and add $[[ x ]]$, with the grade $[[ s2 + s3 ]]$: representing the total
usage of $[[ x ]]$ in $[[ t ]]$.

\subsubsection{Data types}

The synthesis of introduction forms for data types is by the \GRANULEdruleConName rule:
\begin{align*}
  \hspace{-1em}{\footnotesize{
    \synConP
  }}
\end{align*}
where $D$ is the set of data constructors in global scope, e.g., coming from ADT
definitions, including here products, unit, and coproducts with $(,) : A^1 \rightarrow B^1
\rightarrow A \otimes B$, $Unit : [[ Unit ]]$, $\mathsf{inl} : A^1
\rightarrow A \oplus B$, and $\mathsf{inr} : B^1 \rightarrow A \oplus B$.

For a goal type $[[ K {A Many} ]]$ where $K$ is a data type with zero or more
type arguments (denoted by the vector $[[ A Many ]]$), then a constructor term
$[[ Con t1 .. tn ]]$ for $[[ K {A Many} ]]$ is synthesised. The type scheme of
the constructor in $D$ is first instantiated (similar to \textsc{Def} rule),
yielding a type $ [[ {B1 - q1 .*. Bn -
qn -> {K {A Many}}} ]] $. A sub-term is then synthesised for each of the
constructor's arguments $[[ ti ]]$ in the third premise (which is repeated for
each instantiated argument type $[[ Bi ]]$), yielding output contexts $[[ Di
]]$. The output context for the rule's conclusion is obtained by performing a
context addition across all the output contexts generated from the premises,
where each context $[[ Di ]]$ is scaled by the corresponding grade $[[ qi ]]$
from the data constructor in $D$ capturing the fact that each argument $[[ ti
]]$ is used according to $[[ qi ]]$.

Dual to the above, constructor elimination synthesises \textbf{case}
statements with branches pattern matching on each data constructor of the target
data type $[[K {A Many}]]$, with various associated constraints on grades which
require some explanation:
%
\begin{align*}
  \hspace{-5em}{\footnotesize{
    \synCaseP
  }}
\end{align*}
%
where $1 \leq i \leq m$ is used to index the data constructors of which there
are $m$ (i.e., $m = |[[ K {A Many} ]]|$) and
$1 \leq j \leq n$ is used to index the arguments of the $i^{th}$ data constructor.
For brevity, the rule focuses $n$-ary data constructors where $n > 0$.

As with constructor introduction, the relevant data
constructors are retrieved from the global scope $D$ in the first premise.
A data constructor type
is a function type from the constructor's arguments $[[ B1 ]] \ldots [[ Bn ]]$ to
a type constructor applied to zero or more type parameters $[[ K {A Many} ]]$.
However, in the case of nullary
data constructors (e.g., for the unit type), the data constructor type is simply the type
constructor's type with no arguments. For each data constructor $C_{i}$,
we synthesise a term $[[ ti ]]$ from the result type of the data constructor's
type in $D$, binding the data constructor's argument types as fresh assumptions
to be used in the synthesis of $[[ ti ]]$.

To synthesise the body for each branch $i$, the arguments of the
data constructor are bound to fresh variables in the premise,
with the grades from their respective argument types in $D$ multiplied by the
$[[ r ]]$. This follows the pattern typing rule for constructors; a pattern
match under some grade $[[ r ]]$ must bind assumptions that have the capability
to be used according to $[[ r ]]$.

The assumption being eliminated
$[[ x : [K {A Many}] r ]]$ is also included in the premise's context (as in \GRANULEdruleAppName) as we may perform
additional eliminations on the current assumption subsequently if the grade
$[[ r ]]$ allows us. If successful,
this will yield both a term $t_{i}$ and an output context for the
pattern match branch.
The output context can be broken down into three parts:
\begin{enumerate}
\item $[[ Di ]]$ contains any
assumptions from $[[ G ]]$ were used to construct $[[ ti ]]$
\item  $[[ x : [K A] ri ]]$ describes how the assumption $[[ x ]]$ was
used
\item $[[ {{y Vari Var1} : [B1] {s Vari Var1} } , .M. , {y Vari Varn} : [Bn] {s Vari Varn} ]]$ describes how each assumption  $[[ y Vari Varj ]]$ bound in the pattern
match was used in $[[ ti ]]$.
\end{enumerate}
%
This leaves the question of how we calculate the final grade to
attribute to $ [[ x ]]$  in the output context of the rule's conclusion.
For each bound assumption, we generate a fresh grade variable
$[[ s' Vari Varj  ]]$ which represents how that variable was used in $[[ ti ]]$
after factoring out the multiplication by $[[ q Vari Varj ]]$. This is done via the
constraint in the third premise that $ [[
exists {s' Vari Varj} . {s Vari Varj} <= {s' Vari Varj} * {q Vari Varj} <= r * {q Vari Varj} ]]$.
The join of each $[[ s' Vari Varj ]]$ (for each assumption) is then taken to
form a grade variable $[[ Vari s ]]$ which represents the total usage of
$[[ x ]]$ for this branch that arises from the use of assumptions which were
bound via the pattern match (i.e. not usage that arises from reusing $[[x]]$
explicitly inside $[[ ti ]]$). For the output context of the conclusion, we then
take the join of output context from the constructors used. This is extended
with the original $[[ x ]]$ assumption with the output grade consisting of the
join of each $[[ ri ]]$ (the usages of $[[ x ]]$ directly in each branch) plus
the join of each $[[ si ]]$ (the usages of the assumptions that were bound from
matching on a constructor of $[[ x ]]$).

\begin{example}[Example of \textbf{case} synthesis]
%
Consider two possible synthesis results:
%
\begin{align}
\label{eq:case-ex-branchOne}
& [[  x : [Sum Unit A] r, y : [ A ] s , z : [A] {r * q1} |- A =>+ z ; x : [Sum Unit A] 0, y : [A] 0 , z : [A] 1 ]] \\
\label{eq:case-ex-branchTwo}
& [[  x : [Sum Unit A] r, y : [ A ] s |- A =>+ y ; x : [Sum Unit A] 0 , y : [A] 1 ]]
\end{align}
%
We will plug these into the rule for generating case expressions as follows
where in the following instead of using the above concrete grades we have used
the abstract form of the rule (the two will be linked by equations after):
%
\begin{gather*}
  \hspace{-3em}{\footnotesize{
\inferrule*[right=Case]
{
\mathsf{Just} : \forall \overline{\alpha : \kappa} .  [[ A' ^ 1 -> Sum A' Unit ]] \in [[ Defines ]] \\ \\
 \mathsf{Nothing} : \forall \overline{\alpha : \kappa} . [[ Unit ^ 1 -> Sum A' Unit ]] \in [[ Defines ]] \\ \\
  [[ Sig |- inst {A ^ 1 -> Sum A Unit} {A' ^ 1 -> Sum A' Unit} ]] \\ \\
  [[ Sig |- inst {Unit ^ 1 -> Sum A Unit} {Unit ^ 1 -> Sum A' Unit} ]] \\ \\
 \eqref{eq:case-ex-branchOne} \qquad [[  Sig ; x : [Sum Unit A] r, y : [ A ] s , z : [A] {r * q1} |- A =>+ z ; x : [Sum Unit A] 0, y : [A] 0 , z : [A] s1 ]] \\ \\ \\
 \eqref{eq:case-ex-branchTwo} \qquad [[  Sig ; x : [Sum Unit A] r, y : [ A ] s |- A =>+ y ; x : [Sum Unit A] 0 , y : [A] 1 ]] \\ \\
 [[ exists s1' . s1 <= s1' * q1 <= r * q1 ]] \\ \\
 [[ assn s' s1' ]]
}
{
[[ Sig ; x : [Sum Unit A] r, y : [ A ] s  |- A =>+ (case x of {Just z} -> z  ; {Nothing .} -> y) ; {x : [ {Sum Unit A} ] {(0 \/ 0)} + {s'}} , y : [A] {0 \/ 1} ]]
}
  }}
\end{gather*}
%
Thus, to unify \eqref{eq:case-ex-branchOne}
and \eqref{eq:case-ex-branchTwo} with the rule format we
have that  $[[ s1 ]] = 1$ and $[[ q1 ]] = 1$.  Applying these
two equalities as rewrites to the remaining constraint, we have:
%
\begin{align*}
& [[ exists s1' . 1 <= s1' * 1 <= r * 1 ]] \quad \implies \quad [[ exists s1' . 1 <= s1' <= r ]]
\end{align*}
%
These constraints can be satisfied with the natural-number intervals semiring
where $[[ y ]] $ has grade $ [[IntervalSyn 0 1]]$ and $[[ x ]]$ has grade $[[
{IntervalSyn 1 1} ]]$.
\end{example}

Deep pattern matching, over nested data constructors, is handled via inductively
applying the \GRANULEdruleCaseName\ rule but with a post-synthesis refactoring
procedure substituting the pattern match of the inner case statement into the
outer pattern match. For example, nested matching on pairs becomes a single
$\textbf{case}$ with nested pattern matching, simplifying the program:
% (Section~\ref{sec:refactoring}). For example,
\begin{align*}
         &  [[ case x of Pair y1 y2 -> case y1 of Pair z1 z2 -> z2 ]] \\
\textit{(rewritten to)} \; \leadsto \;\; &  [[ case x of Pair {Pair z1 z2} y2 -> z2 ]]
\end{align*}


\subsubsection{Recursion}
%\label{sec:recursion}

Synthesis permits recursive definitions, as well as programs which may make use
of calls to functions from a user-supplied context of function definitions in
scope (see Section~\ref{sec:examples}). Synthesis of non-recursive function
applications may take place arbitrarily, however, synthesising a recursive
function definition application requires more care. To ensure that a synthesised
programs terminates, we only permit synthesis of terms which are
\textit{structurally recursive}, i.e., those which apply the recursive
definition to a sub-term of the function's inputs~\citep{oserathesis}.

Synthesis rules for recursive types ($\mu$-types) are
straightforward:\footnote{Though $\mu$ types are equi-recursive, we make
explicit the synthesis rules here which maps more closely to the implementation
where iterative deepening information needs to be tracked at the points of using
$\mu_\textsc{L}$ and  $\mu_\textsc{R}$.}
\begin{align*}
  \begin{array}{cc}
  \synMuR & \synMuL
  \end{array}
\end{align*}
This $\mu_\textsc{R}$ rule states that to synthesise a recursive data structure
of type $\mu X . [[ A ]]$, we must be able to synthesise $[[ A ]]$ with $\mu X .
[[ A ]]$ substituted for the recursion variables $X$ in $[[ A ]]$. For example,
if we wish to synthesise a list data type \granin{List a} with constructors
\granin{Nil} and \granin{Cons a (List a)}, then when choosing the \granin{Cons}
constructor in the $\mu_\textsc{R}$ rule, the type of this constructor requires
us to re-apply the $\mu_\textsc{R}$ rule, to synthesise the recursive part of
\granin{Cons}. Elimination of a recursive data structure may be synthesised
using the $\mu_\textsc{L}$ rule. In this rule, we have some recursive data type
$\mu X . [[ A ]]$ in our context which we may wish to pattern match on via the
$\textsc{C}_\textsc{L}$ rule. To do this, the assumption is bound in the premise
with the type $[[ A ]]$, substituting $\mu X. [[ A]]$ for the recursion
variables $X$ in $[[ A ]]$.

Recursive data structures present a challenge in the implementation. For our
list data type, how do we prevent our synthesis tool from simply applying the
$\mu_\textsc{L}$ rule, followed by the $\textsc{C}_\textsc{L}$ rule on the
\granin{Cons} constructor ad infinitum? We resolve this issue using an
\textit{iterative deepening} approach to synthesis similar to the approach used
by \textsc{Myth}~\citep{oserathesis}. Programs are synthesised with elimination
(and introduction) forms of constructors restricted up to a given depth. If no
program is synthesised within these bounds, then the depth limits are
incremented. Combined with focusing (see Section~\ref{section:graded-base-focusing}), this
provides the basis for an efficient implementation of the above rules.

% The benchmarks in Section~\ref{sec:evaluation} make heavy use of polymorphism.

\section{Input-Output Examples}

\label{sec:examples}

When specifying the synthesis context of top-level definitions, the user may
also supply a series of input-output examples showcasing desired behaviour. Our
approach to examples is deliberately na\"{i}ve; we evaluate a fully synthesised
candidate program against the inputs and check that the results match the
corresponding outputs. Unlike many sophisticated example-driven synthesis tools,
the examples here do not themselves influence the search procedure, and are used
solely to allow the user to clarify their intent. This lets us consider the
effectiveness of basing the search primarily around the use of grade
information. An approach to synthesis of resourceful programs with examples
closely integrated into the search as well is further work.

We augmented the Granule language with first-class syntax for specifying
input-output examples, both as a feature for aiding synthesis but also for
aiding documentation that is type checked (and therefore more likely to stay
consistent with a code base as it evolves). Synthesis specifications are written
in Granule directly above a program hole (written using \granin{?}) using the
\granin{spec} keyword. The input-output examples are then listed per-line.
\begin{granule}
tail : forall { a : Type } . List a %0..1 -> List a
spec
  tail (Cons 1 Nil) = Nil;
  tail (Cons 1 (Cons 2 Nil)) = Cons 2 Nil;
tail = ?
\end{granule}
Any synthesised term must then behave according to the supplied examples. This
\granin{spec} structure can also be used to describe additional synthesis
components that the user wishes the tool to make use of. These components
comprise a list of in-scope definitions separated by commas. The user can choose
to annotate each component with a grade, describing the required usage in the
synthesised term. This defaults to a $1$ grade if not specified. For example,
the specification for a function which returns the length of a list might be:
\begin{granule}
length : forall { a : Type } . List a %0..$\infty$. -> N
spec
    length Nil = Z;
    length (Cons 1 Nil) = S Z;
    length (Cons 1 (Cons 1 Nil)) = S (S Z);
    length %0..$\infty$.
length = ?
\end{granule}
with the following resulting program produced by our synthesis algorithm (on average
in about 400ms on a standard laptop, see Section~\ref{section:graded-base-evaluation} where this is one of the benchmarks for evaluation):
\begin{granule}
length Nil = Z;
length (Cons y z) = S (length z)
\end{granule}

\section{Post-Synthesis Refactoring}
\label{sec:graded-base-refactoring}

In Section~\ref{sec:linear-base-refactoring}, we considered how our synthesised
terms could be refactored into a more idiomatic programming style. Those same
refactoring transformations also apply to our calculus here, along with the
additional treatment relating to case statements.

Recall that the $\textsc{C}_{L}$ binds a data constructor's patterns as a series
of variables. Synthesising a pattern match over a nested data structure
therefore yields a term such as:
\begin{granule}
  case x of
    C_1 y ->
      case y of
        D_1 z -> ...
        D_2 z -> ...
    C_2 y ->
      case y of
        D_1 z -> ...
        D_2 z -> ...
\end{granule}
which would be rather unnatural for a programmer to write. Nested case statements are therefore folded together to yield a single case statement which pattern matches over all combination of patterns from each statement. The above cases are then transformed into the much more compact and readable single case:
\begin{granule}
  case x of
    C_1 (D_1 z) -> ...
    C_1 (D_2 z) -> ...
    C_2 (D_1 z) -> ...
    C_2 (D_2 z) -> ...
\end{granule}
        Furthermore, pattern matches over a function's arguments in the form of case statements are refactored such that a new function equation is created for each unique combination of pattern match. In this way, a refactored program should only contain case statements that arise from pattern matching over the result of an application.
\begin{granule}
neg : Bool %1 -> Bool %1
neg x = case x of
          True -> False;
          False -> True
\end{granule}
is refactored into:
\begin{granule}
neg : Bool %1 -> Bool %1
neg True = False;
neg False = True
\end{granule}
The exception to this is where the scrutinee of a case statement is re-used
inside one of the case branches, in which case refactoring would cause us to throw
away the binding of the scrutinee's name and so it cannot be folded into the head pattern match, for example:
\begin{granule}
last : forall { a : Type } . (List a) %0..$\infty$ -> Maybe a
spec
    last Nil = Nothing;
    last (Cons 1 Nil) = Just 1;
    last (Cons 1 (Cons 2 Nil)) = Just 2;
    last %0..$\infty$
last Nil = Nothing;
last (Cons y z) =
    (case z of
      Nil -> Just y;
      Cons u v -> last z)
\end{granule}
A final minor refactoring procedure is to refactor a variable pattern into a
wildcard pattern, in the case that the bound variable is not used inside the
body of the case branch: 
\begin{granule}
throwAway : forall { a : Type } . a %0..$\infty$ -> ()
throwAway x = ()
\end{granule}
is refactored into: 
\begin{granule}
throwAway : forall { a : Type } . a %0..$\infty$ -> ()
throwAway _ = ()
\end{granule}
For such a scenario to occur a pattern must typed with a grade that is
approximatable by 0.


\section{Focusing}
\label{section:graded-base-focusing}
As in Chapter~\ref{chapter:core}, the synthesis rules as we have presented them
thus far are far too non-deterministic to form the basis of an
implementation through direct translation into code. Again, we apply the
technique of focusing~\citep{focusing} to our calculus, yielding a
\emph{focused} synthesis calculus which imposes an ordering on when rules may be
applied at each stage of synthesis. 

We have already outlined the principles behind focusing in
Section~\ref{sec:linear-base-focusing}, and thus opt not to repeat ourselves here.
Instead, we merely present the focused form of the fully graded synthesis
calculus in
Figures~\ref{fig:focus-graded-right-async},~\ref{fig:focus-graded-left-async},~\ref{fig:focus-graded-focus},~\ref{fig:focus-graded-right-sync}, and~\ref{fig:focus-graded-left-sync},
and state that focusing is sound (Lemma~\ref{lemma:graded-focus-sound}). The
proof of soundness of focusing can be found in Section~\ref{proof:focus-graded-sound} of
Appendix~\ref{appendix:proofs}.



% \tikzset{
% ->, % makes the edges directed
% node distance=5cm, % specifies the minimum distance between two nodes. Change if necessary.
% every state/.style={thick, fill=gray!10}, % sets the properties for each ’state’ node
% initial text=$ $, % sets the text that appears on the start arrow
% }

% \begin{figure}[H] % ’ht’ tells LaTeX to place the figure ’here’ or at the top of the page
% \centering 

% \scalebox{0.85}{
% \begin{tikzpicture}[every text node part/.style={align=center}]
% \node[state, initial, draw] (RA) {\textsc{Right Async} \\ $ \Gamma ; \Omega \vdash A \Uparrow\ \Rightarrow t\ |\ \Delta $};
% \node[state] at (10,  0) (LA) { \textsc{Left Async} \\ $\Gamma ; \Omega \Uparrow\ \vdash A \Rightarrow t\ |\ \Delta $};
% \node[state] at (5, -5) (F) { \textsc{Focus} \\ $\Gamma ; \emptyset \Uparrow\ \vdash A \Rightarrow t\ |\ \Delta $};
% \node[state] at (0, -10) (RS) { \textsc{Right Sync} \\ $\Gamma ; \emptyset \vdash A\ \Downarrow\ \Rightarrow t\ |\ \Delta $};
% \node[state] at (10, -10) (LS) { \textsc{Left Sync} \\ $\Gamma ; [[ x : B ]] \Downarrow\ \vdash A \Rightarrow t\ |\ \Delta $};
% \node[state, accepting] at (5, -12) (V) { \textsc{Var} \\ $\Gamma ; [[ x : A ]] \Downarrow\ \vdash A \Rightarrow t\ |\ \Delta $};
% \draw (RA) edge[loop above] node{$\rightarrow_{\textsc{R}}$} (RA)
% (RA) edge[above, bend left] node{$\Uparrow_{\textsc{R}}$} (LA)
% (LA) edge[loop above] node{$\textsc{C}_{\textsc{L}}$, $\Box_{\textsc{L}}$, $\Uparrow_{\textsc{L}}$ } (LA)
% % (LA) edge[loop right] node{$\Uparrow_{L}$} (LA)
% (LA) edge[left, bend right] node{$\textsc{C}_{\textsc{L}}$, $\Box_{\textsc{L}}$, $\Uparrow_{\textsc{L}}$ \ \ \ \ \\  } (F)
% % (LA) edge[right, bend left] node{$\Uparrow_{L}$} (F)
% (F) edge[below, bend right] node{\ \ \ \  $\textsc{F}_{\textsc{R}}$} (RS)
% (RS) edge[left, bend left] node{$\Downarrow_{\textsc{L}}$} (RA)
% (F) edge[below, bend left] node{$\textsc{F}_{\textsc{L}}$\ \ } (LS)
% (LS) edge[right, bend right] node{$\Downarrow_{\textsc{L}}$} (LA)
% (LS) edge[below, bend right] node{$\rightarrow_{\textsc{L}}$} (RS)
% (LS) edge[loop below] node{$\rightarrow_{\textsc{L}}$} (LS)
% (RS) edge[loop below] node{$\textsc{C}_{\textsc{R}}$, $\Box_{\textsc{R}}$} (RS)
% (LS) edge[below, bend left] node{\\[0.1em] \ \ \ $\textsc{Var}$ } (V)
% ;
% \end{tikzpicture}
% }
% \caption{Focusing state machine for the fully graded synthesis calculus}
% \label{fig:focusingFSM-graded}
% \end{figure}

\begin{restatable}[Soundness of focusing for graded-base synthesis]{lemma}{gradedBaseFocusingSoundness}
  For all contexts $[[ G ]]$, $[[ O ]]$ and types $[[ A ]]$:
  \begin{align*}
    {\footnotesize{
  \hspace{-3.5em}\begin{array}{lll}
   1.\ Right\ Async: & [[ Defs ; Sig; G ; O |- A async => t ; D ]] \quad &\implies \quad [[ Defs ]] ; [[ Sig ]] ; [[ G , O ]] \vdash [[ A ]] \Rightarrow [[ t ]] \mid [[ D ]]\\
   2.\ Left\ Async: & [[ Defs ; Sig; G ; O async |- B => t ; D ]] \quad &\implies \quad [[ Defs ]] ; [[ Sig ]]  ; [[ G , O ]] \vdash [[ B ]] \Rightarrow [[ t ]] \mid [[ D ]]\\
   3.\ Right\ Sync: & [[ Defs ]] ; [[ Sig ]] ; [[ G ]] ; \emptyset \vdash [[ A ]] \Downarrow\ \ \Rightarrow [[ t ]] \mid\  [[ D ]] \quad &\implies \quad [[ Defs ]] ; [[ Sig ]] ; [[ G ]] \vdash [[ A ]] \Rightarrow [[ t ]] \mid [[ D ]]\\
   4.\ Left\ Sync: & [[ Defs ; Sig ; G ; {x : [A] r} sync |- B => t ; D ]] \quad &\implies \quad [[ Defs ]] ; [[ Sig ]] ; [[ G, x : [ A] r ]] \vdash [[ B ]] \Rightarrow [[ t ]] \mid [[ D ]]\\
   5.\ Focus\ Right: & [[ Defs ]] ; [[ Sig ]] ; [[ G ]] ; \emptyset \Uparrow\ \vdash [[ B]] \Rightarrow [[ t]] \mid\ [[ D ]] \quad &\implies \quad [[ Defs ]] ; [[ Sig ]] ;  [[ G ]] \vdash [[ B ]] \Rightarrow [[ t ]] \mid [[ D ]]\\
   6.\ Focus\ Left: & [[ Defs ]] ; [[ Sig ]]; [[ G ]], [[ x : [A] r ]] ; \emptyset \Uparrow\ \vdash [[ B]] \Rightarrow [[t ]] \mid\ [[ D ]] \quad &\implies \quad [[ Defs ]] ; [[ Sig ]] ; [[ G, x : [A ] r ]] \vdash [[ B ]] \Rightarrow [[ t ]] \mid [[ D ]]
  \end{array}
    }}
  \end{align*}
i.e. $[[ t ]]$ has type $[[ A ]]$
under context $[[ D ]]$,
which contains variables with grades reflecting their use in $[[ t ]]$.
%Appendix~\ref{sec:soundness-proofs} provides the proof.
\label{lemma:graded-focus-sound}
  \end{restatable}

  \begin{figure}[H]
    \begin{align*}
      {\footnotesize{
  \begin{array}{c}
      \fsynAbsP
      \\[1.25em]
      \fsynTopP
      \\[1.25em]
      \fsynRAsyncTransP
    \end{array}
      }}
    \end{align*}
    \caption{Right Async rules of the focused fully graded synthesis calculus}
    \label{fig:focus-graded-right-async}
  \end{figure}

\begin{figure}[H]
  \begin{align*}
  {\footnotesize{
\hspace{-4em}\begin{array}{c}
      \fsynCaseP
      \\[1.25em]
      \fsynMuLP
      \\[1.25em]
      \fsynUnboxP
      \\[1.25em]
      \fsynLAsyncTransP
  \end{array}
  }}
  \end{align*}
  \caption{Left Async rules of the focused fully graded synthesis calculus}
  \label{fig:focus-graded-left-async}
\end{figure}

\begin{figure}[H]
  \begin{align*}
    {\footnotesize{
\begin{array}{c}
      \fsynFocusRP
      \\[1.25em]
      \fsynFocusLP
  \end{array}
    }}
  \end{align*}
  \caption{Focus rules of the focused fully graded synthesis calculus}
  \label{fig:focus-graded-focus}
\end{figure}

\begin{figure}[H]
  \begin{align*}
    {\footnotesize{
\begin{array}{c}
      \fsynConP
      \\[1.25em]
      \fsynBoxP
      \\[1.25em]
      \fsynMuRP
      \\[1.25em]
      \fsynRSyncTransP
  \end{array}
    }}
  \end{align*}
  \caption{Right Sync rules of the focused fully graded synthesis calculus}
  \label{fig:focus-graded-right-sync}
\end{figure}


\begin{figure}[H]
  \begin{align*}
    {\footnotesize{
\hspace{-3em}\begin{array}{c}
      \fsynAppP
      \\[1.25em]
      \fsynVarP
      \\[1.25em]
      \fsynDefP
      \\[1.25em]
      \fsynLSyncTransP
  \end{array}
    }}
  \end{align*}
  \caption{Left Sync, Var, and Def rules of the focused fully graded synthesis calculus}
  \label{fig:focus-graded-left-sync}
\end{figure}


\section{Evaluating the Synthesis Calculus}
\label{section:graded-base-evaluation}

In evaluating our fully graded synthesis approach and tool, we made the following hypotheses:
\begin{enumerate}
\item[H1.] (\textbf{Expressivity; less consultation}) The use of grades in synthesis results in a synthesised program
  that is more likely to have the behaviour desired by the user; the user needs to request
  fewer alternate synthesised results (\emph{retries}) and thus is consulted less in order to arrive at the desired program. %When
%        synthesising a program from a graded type, the user can refine
%        their synthesis specification with input-output examples, to accurately
 %       convey their intent.
        %If the same example set is used to synthesis a graded type
        %vs that type without grades, then in the non-graded case the resulting
        %programs will often be ill-resources, type checker
        %will frequently have to be consulted to check whether a candidate
        %program type checks against the original graded type.
\item[H2.] (\textbf{Expressivity; fewer examples}) Grade-and-type directed
  synthesis requires fewer input-output examples to arrive at the desired
  program compare with a purely type-driven approach. % if the candidate programs do not consult the type checker.
\item[H3.] (\textbf{Performance; more pruning}) The ability to prune resource-violating candidate programs from the search
        tree leads to a synthesised program being found more quickly when
        synthesised from a graded type compared with
        the same type but without grades (purely type-driven approach).
\end{enumerate}

\subsection{Methodology}
%
To evaluate our approach, we collected a suite of benchmarks comprising graded
type signatures for common transformations on data structures such as lists,
streams, booleans, option (`maybe') types, unary natural numbers, and binary
trees. We draw many of these from the benchmark suite of the \textsc{Myth}
synthesis tool~\citep{oseraMYTH1}.  Benchmarks are divided into classes based on
the main data type, with an additional category of miscellaneous programs. The
type schemes for the full suite of benchmarks can be found in
Table~\ref{tab:problems} while~\ref{tab:datatypes} lists the data types used by the 
benchmarking problems. The complete synthesised programs, including examples
used and synthesis contexts can be found in Section~\ref{sec:graded-benchmarks}
of Appendix~\ref{appendix:benchmarks}. 

To compare, in various ways, our grade-and-type-directed
synthesis to traditional type-directed synthesis, each benchmark
signature is also ``de-graded'' by replacing all grades in the goal
with \granin{Any} which is the only element of the singleton
\granin{Cartesian} semiring in Granule. When synthesising in this
semiring, we can forgo discharging grade constraints in the SMT solver
entirely.  Thus, synthesis for Cartesian grades degenerates to
typed-directed synthesis following our rules.

To assess hypothesis 1 (grade-and-type directed leads to less consultation
/ more likely to synthesise the intended program) we perform grade-and-type
directed synthesis on each benchmark problem and type-directed synthesis
on the corresponding de-graded version. For the de-graded
versions, we record the number of
retries $N$ needed to arrive at a well-resourced answer by
type checking the output programs against
the original graded type signature, retrying if the program is not well-typed
(essentially, not well-resourced). This provides a means to check whether a program
may be as intended without requiring user input. In each
case we also compared whether the resulting programs from synthesis via graded-and-type directed
vs. type-directed with retries (on non-well-resourced outputs) were equivalent.

To assess hypothesis 2 (graded-and-type directed requires
fewer examples than type-directed), we run the de-graded (Cartesian)
synthesis with the smallest set of examples which
leads to the model program being synthesised (without any retries).
To compare across approaches to the state-of-the-art
type-directed approach, we also run
a separate set of experiments comparing the minimal number
of examples required to synthesise in Granule (with grades)
vs. \textsc{Myth}.

To assess hypothesis 3 (grade-and-type-directed faster than
type-directed) we compare performance in the graded setting to the
non-graded Cartesian setting. Comparing our tool for speed
against another type-directed (but not graded-directed) synthesis tool
is likely to be largely uninformative due to differences in
implementation approach obscuring any meaningful comparison. Thus, we
instead compare timings for the graded approach and de-graded approach
within Granule. We also record the number of search paths taken (over
all retries) to assess the level of pruning in graded vs
non-graded.

% In which
% case, for each benchmark we need a model solution against which we can compare.
% %was not equivalent to the synthesised graded term .
% In a real life scenario, the oracle is a user who manually accepts or
% rejects programs, asking the synthesis algorithm for the next possible output
% until it matches the desired program behaviour (model solution).
% We consider that such an oracle request also has a time cost.
% We model this cost by calculating total synthesis time plus
% a simple model of the manual, user-driven behaviour by multiplying each rejection
% from the oracle by a 1 second penalty (a conservative estimate of how long it takes
% a user to inspect a program for accept/reject).


We ran our synthesis tool on each benchmark for both the graded
type and the de-graded Cartesian case, computing
the mean after 10 trials for timing data. Benchmarking was carried out using
version 4.12.1 of Z3 on an M1 MacBook Air with 16 GB of RAM.
A timeout limit of 10 seconds was set for synthesis.

\subsection{Results and Analysis}


Table~\ref{tab:results-graded} records the results comparing grade-and-type
synthesis vs. the Cartesian (de-graded) type-directed synthesis.  The
left column gives the benchmark name, number of top-level definitions
in scope that can be used as components (size of the synthesis
context) labelled $\textsc{Ctxt}$, and the minimum number of examples
needed (\#/Exs) to synthesise the Graded and Cartesian programs. In
the Cartesian setting, where grade information is not available, if we
forgo type checking a candidate program against the original graded
type then additional input-output examples are required to provide a
strong enough specification such that the correct program is
synthesised (see H3). The number of additional examples is given in
parentheses for those benchmarks which required these additional
examples to synthesise a program in the Cartesian setting.

Each subsequent results column records: whether a program was synthesised
successfully \success{} or not \fail{} (due to timeout or no solution found),
the mean synthesis time ($\mu{}T$) or if timeout occurred, and
the number branching paths (Paths) explored in the search space.

The first results column (Graded) contains the results for graded synthesis. The
second results column (Cartesian + Graded type-check) contains the results for
synthesising a program in the Cartesian (de-graded) setting, using the same
examples set as the Graded column, and recording the number of retries
(consultations of the type-checker) \textsc{N} needed to reach a well-resourced
program. In all cases, this resulting program in the Cartesian column was
equivalent to that generated by the graded synthesis, none of which needed any
retries (i.e., implicitly $N = 0$ for graded synthesis). H1 is confirmed by the
fact that $N$ is greater than $0$ in 29 out of 46 benchmarks (60\%), i.e., the
Cartesian case does not synthesis the correct program first time and needs
multiple retries to reach a well-resource program, with a mean of $19.60$
retries and a median of $4$ retries.

For each row, we highlight the column which synthesised a result the fastest in
$\highlight{\text{yellow}}$. The results show that in $17$ of the $46$ benchmarks
(37\%) the graded approach out-performed non-graded synthesis. This contradicts
hypothesis 3 somewhat: whilst type-directed synthesis often requires multiple
retries (versus no retries) it still outperforms the graded equivalent. This
appears to be due to the cost of our SMT solving procedure which must first
compile a first-order theorem on grades into the SMT-lib file format, start up
Z3, and then run the solver. Considerable amounts of system overhead are
incurred in this procedure. A more efficient implementation calling Z3 directly
(e.g., via a dynamic library call) may give more favourable results here.
However, H3 is still somewhat supported: the cases in which the graded does
outperform the Cartesian are those which involve considerable complexity in
their use of grades, such as \granin{stutter}, \granin{inc}, and \granin{bind}
for lists, as well as \granin{sum} for both lists and trees. In each of these
cases, the Cartesian column is significantly slower, even timing out for
\granin{stutter}; this shows the power of the graded approach. Furthermore, we
highlight the column with the smallest number of synthesis paths explored in
$\newhighlight{\text{blue}}$, observing that the number of paths in the graded
case is always the same or less than that those in the Cartesian+graded type
check case (apart from Tree stutter). 

Interestingly the paths explored are sometimes the same because we use
backtracking search in the Cartesian+Graded type check case where, if an output
program fails to type check against the graded type signature, the search
backtracks rather than starting again.

Confirming H2, we find that for the non-graded setting without graded
type checking, further examples are required to synthesise the same program as
the graded in $20$ out of $46$ (43\%) cases. In these cases, an average of
$1.25$ additional examples was required.

\begin{table}[H]
    \begin{center}
        \begin{tabular}{p{4.25em}l|l}
            \hline \multicolumn{2}{c}{{Data Type}} & \multicolumn{1}{|c}{Type Scheme} \\ \hline
\hline \textbf{List} &
        Cons      & $\forall a . a^{1} \rightarrow \text{List}\ a^{1} \rightarrow \text{List}\ a$\\ &
        Nil       & $\forall a . \text{List}\ a$ \\
\hline \textbf{Stream} &
        Next      & $\forall a . a^{1} \rightarrow \text{Stream}\ a^{1} \rightarrow \text{Stream}\ a$ \\
\hline \textbf{Bool} &
        True      & $ \text{Bool} $ \\ &
        False     & $ \text{Bool} $ \\
\hline \textbf{Maybe} &
        Just      & $ \forall a . a^{1} \rightarrow \text{Maybe}\ a $ \\ &
        Nothing   & $ \forall a . \text{Maybe}\ a $ \\
\hline \textbf{N} &
        S         & $ \text{N}^{1} \rightarrow \text{N} $ \\ &
        Z         & $ \text{N} $ \\
\hline \textbf{Tree} &
        Node      & $ \forall a . \text{Tree}\ a^{1} \rightarrow a^{1} \rightarrow \text{Tree}\ a^{1} \rightarrow \text{Tree}\ a$ \\ &
        Leaf      & $ \forall a . \text{Tree}\ a $ \\
        \end{tabular}
    \end{center}
\caption{Data types used in synthesis benchmarking problems}
\label{tab:datatypes}
\end{table}

\label{app:list-of-types}
        \begin{table}[H]
                {\footnotesize{
                \begin{center}
                \setlength{\tabcolsep}{0.3em}
                \scalebox{0.9}{
                \begin{tabular}{p{1.25em}c|l}
                \hline \multicolumn{2}{c}{{Problem}} & \multicolumn{1}{|c}{Type Scheme} \\ \hline
                    \hline \multirow{19}{*}{{\rotatebox{90}{\textbf{List}}}} &
                append      & $\forall a . \text{List}\ a^1 \rightarrow a^1 \rightarrow \text{List}\ a $\\ &
                concat      & $\forall a . \text{List}\ a^{1..\infty} \rightarrow \text{List}\ a^{1..\infty} \rightarrow \text{List}\ a$\\ &
                empty       & $\forall a . \text{Unit}^1\ \rightarrow \text{List}\ a$\\ &
                snoc        & $\forall a . \text{List}^{1..\infty}\ \rightarrow a^{1..\infty}  \rightarrow \text{List}\ a$\\ &
                drop        & $\forall a . \text{N}^{0..\infty}\ \rightarrow \text{List}^{0..\infty}\ \rightarrow \text{List}\ a$\\ &
                flatten     & $\forall a . \text{List}\ (\text{List}\ a)^{0..\infty} \rightarrow \text{List}\ a$\\ &
                bind        & $\forall a\ b. \text{List}\ a^{1..\infty} \rightarrow (a^{1..\infty} \rightarrow \text{List}\ b)^{0..\infty} \rightarrow \text{List}\ b$\\ &
                return      & $\forall a . a^{1} \rightarrow \text{List}\ a$\\ &
                inc         & $\text{List N}^{1..\infty} \rightarrow \text{List N}$\\ &
                head        & $\forall a . \text{List}\ a^{0..1} \rightarrow a^{0..1} \rightarrow a t$\\ &
                tail        & $\forall a . \text{List}\ a^{0..1} \rightarrow \text{List}\ a$\\ &
                last        & $\forall a . \text{List}\ a^{0..\infty} \rightarrow \text{Maybe}\ a$\\ &
                length      & $\forall a . \text{List}\ a^{} \rightarrow \text{N}$\\ &
                map         & $\forall a\ b . (a^{1..\infty} \rightarrow b)^{0..\infty} \rightarrow \text{List}\ a^{1..\infty} \rightarrow \text{List}\ b$\\ &
                replicate5  & $\forall a . a^{5} \rightarrow \text{List}\ a$\\ &
                replicate10 & $\forall a . a^{10} \rightarrow \text{List}\ a$\\ &
                replicateN  & $\forall a . \text{N}^{0..\infty} \rightarrow a^{0..\infty} \rightarrow \text{List} a$\\ &
                stutter     & $\forall a . \text{List}\ (a\ [2])^{1..\infty} \rightarrow \text{List}\ a$\\ &
                sum         & $\text{List N}^{0..\infty} \rightarrow \text{N}$ \\
                    \hline \multirow{5}{*}{{\rotatebox{90}{\textbf{Stream}}}} &
                build       & $\forall a . a^{1..1} \rightarrow \text{Stream}\ a^{1..1} \rightarrow \text{Stream}\ a$\\ &
                map         & $\forall a\ b . \text{Stream}\ a^{1..\infty} \rightarrow (a^{1..\infty} \rightarrow b)^{1..\infty} \rightarrow \text{Stream}\ b $\\ &
                take1       & $\forall a . \text{Stream}\ a^{0..1} \rightarrow a $\\  &
                take2       & $\forall a . \text{Stream}\ a^{0..1} \rightarrow (a,\ a) $\\ &
                take3       & $\forall a . \text{Stream}\ a^{0..1} \rightarrow (a,\ (a,\ a))$\\
                    \hline \multirow{5}{*}{{\rotatebox{90}{\textbf{Bool}}}} &
                neg         & $\text{Bool}^{1}\ \rightarrow \text{Bool}$\\ &
                and         & $\text{Bool}^{1}\ \rightarrow \text{Bool}^{1}\ \rightarrow \text{Bool}$\\ &
                impl        & $\text{Bool}^{1}\ \rightarrow \text{Bool}^{1}\ \rightarrow \text{Bool}$\\ &
                or          & $\text{Bool}^{1}\ \rightarrow \text{Bool}^{1}\ \rightarrow \text{Bool}$\\ &
                xor         & $\text{Bool}^{1}\ \rightarrow \text{Bool}^{1}\ \rightarrow \text{Bool}$\\
                    \hline \multirow{7}{*}{{\rotatebox{90}{\textbf{Maybe}}}} &
                bind        & $\forall a\ b . \text{Maybe}\ a^{1..1} \rightarrow (a^{1..1} \rightarrow \text{Maybe}\ b)^{0..1} \rightarrow \text{Maybe}\ b$\\ &
                fromMaybe   & $\forall a . \text{Maybe}\ a^{1..1} \rightarrow a^{0..1} \rightarrow a$\\ &
                return      & $\forall a . a^{1} \rightarrow \text{Maybe}\ a$ \\ &
                isJust      & $\forall a . \text{Maybe}\ a^{1} \rightarrow \text{Bool}$ \\ &
                isNothing   & $\forall a . \text{Maybe}\ a^{1} \rightarrow \text{Bool}$ \\ &
                map         & $\forall a\ b . (a^{1..1} \rightarrow b)^{0..1}  \rightarrow \text{Maybe}\ a^{1..1} \rightarrow \text{Maybe}\ b $ \\ &
                mplus       & $\forall a\ b . \text{Maybe}\ a^{1} \rightarrow \text{Maybe}\ b^{1} \rightarrow \text{Maybe}\ (a,\ b)$ \\
                    \hline \multirow{4}{*}{{\rotatebox{90}{\textbf{Nat}}}} &
                isEven      & $\text{N}^{1..\infty} \rightarrow \text{Bool}$ \\ &
                pred        & $\text{N}^{1} \rightarrow \text{N}$ \\ &
                succ        & $\text{N}^{1} \rightarrow \text{N}$ \\ &
                sum         & $\text{N}^{1..\infty} \rightarrow \text{N}^{1..\infty} \rightarrow \text{N}$ \\
                    \hline \multirow{3}{*}{{\rotatebox{90}{\textbf{Tree}}}} &
                map         & $\forall a\ b . (a^{1..\infty} \rightarrow b)^{0..\infty} \rightarrow \text{Tree}\ a^{1..\infty} \rightarrow \text{Tree}\ b$ \\ &
                stutter     & $\forall a . \text{Tree}\ (a\ [2])^{1..\infty} \rightarrow \text{Tree}\ (a,\ a)$ \\ &
                sum         & $\text{Tree N}^{0..\infty} \rightarrow \text{N}$ \\
                    \hline \multirow{3}{*}{{\rotatebox{90}{\textbf{Misc}}}} &
                compose     & $\forall k : \text{Coeffect}, n\ m : k, a\ b\ c : \text{Type} . (a^{m} \rightarrow b)^{n} \rightarrow (b^{n} \rightarrow c)^{1 : k} \rightarrow a^{n \cdot m} \rightarrow c $ \\   &
                copy        & $\forall a . a^{2} \rightarrow (a,\ a)$ \\  &
                push        & $\forall k : \text{Coeffect}, c : k, a\ b : \text{Type} . (a^{1} \rightarrow b)^{c} \rightarrow a^{c} \rightarrow b\ [c]$
            \end{tabular}}
                \end{center}}}
                \caption{Type schemes for synthesis benchmarking results}
                \label{tab:problems}
                \end{table}


%
        % \begin{table}[t]
        %         {\footnotesize{
        %         \begin{center}
        %         \setlength{\tabcolsep}{0.3em}
        %         \scalebox{0.70}{
        %         \begin{tabular}{p{1.25em}cc|p{0.75em}rc|p{0.75em}rcc|p{0.75em}rc} & & &
        %         \multicolumn{3}{c|}{Graded}&\multicolumn{4}{c|}{Cartesian}&\multicolumn{3}{c|}{Cartesian (No Retries)} \\ \hline \multicolumn{2}{c}{{Problem}}& \multicolumn{1}{c|}{{Ctxt}} & & \multicolumn{1}{c}{$\mu{T}$ (ms)} & \multicolumn{1}{c|}{{\#/Exs.}} & & \multicolumn{1}{c}{$\mu{T}$ (ms)} & \multicolumn{1}{c}{\textsc{N}} & \multicolumn{1}{c|}{$\mu{T}$ + OracleT (ms)}  & & \multicolumn{1}{c}{$\mu{T}$ (ms)} & \multicolumn{1}{c|}{{\#/Exs.}}\\ \hline
        %         \hline \multirow{19}{*}{{\rotatebox{90}{\textbf{List}}}} &
        %         append &   0       & \success{} & {\highlight{$ 114.19 (\stderr{  1.22}) $}} &   0       & \success{} & 281.02 (\stderr{  0.80}) &   8       & 383.40 (\stderr{  1.48}) & \success{} & 305.92 (\stderr{  5.24}) &   1      \\
        %         %
        %          &
        %         concat &   1       & \success{} & {\highlight{$ 1129.85 (\stderr{  0.88}) $}} &   0       & \success{} & 2372.70 (\stderr{  2.55}) &  12       & 2967.16 (\stderr{  2.65}) & \success{} & 2779.17 (\stderr{ 22.62}) &   3      \\
        %         %
        %          &
        %         empty &   0       & \success{} & {\highlight{$   5.29 (\stderr{  0.03}) $}} &   0       & \success{} &   5.38 (\stderr{  0.02}) &   0       &   6.57 (\stderr{  0.02}) & \success{} &   5.54 (\stderr{  0.16}) &   0      \\
        %         %
        %          &
        %         snoc &   1       & \success{} & {\highlight{$ 2183.50 (\stderr{  1.08}) $}} &   1       & \success{} & 4011.04 (\stderr{  2.69}) &   8       & 5049.18 (\stderr{  2.83}) & \success{} & 4118.02 (\stderr{ 42.14}) &   1      \\
        %         %
        %          &
        %         drop &   1       & \success{} & {\anotherhighlight{$1209.60 (\stderr{  1.41})$}} &   1       & \success{} & 1568.58 (\stderr{  0.49}) &   8       & 1977.29 (\stderr{  0.84}) & \success{} & {\highlight{$ 831.05 (\stderr{  9.60}) $}} &   1      \\
        %         %
        %          &
        %         flatten &   2       & \success{} & 1397.15 (\stderr{  0.64}) &   1       & \success{} & {\newhighlight{$ 831.18 (\stderr{  0.84}) $}} &   8       & 1347.12 (\stderr{  0.90}) & \success{} & {\highlight{$ 913.95 (\stderr{ 12.44}) $}} &   1      \\
        %         %
        %          &
        %         bind &   2       & \success{} & {\highlight{$  64.68 (\stderr{  0.17}) $}} &   0       & \success{} & 269.95 (\stderr{  0.65}) &  18       & 891.25 (\stderr{  1.82}) & \success{} & 276.54 (\stderr{  3.21}) &   2      \\
        %         %
        %          &
        %         return &   0       & \success{} & {\highlight{$  20.50 (\stderr{  0.10}) $}} &   0       & \success{} & {\newhighlight{$  19.83 (\stderr{  0.10}) $}} &   4       &  41.29 (\stderr{  0.20}) & \success{} &  21.10 (\stderr{  0.26}) &   1      \\
        %         %
        %          &
        %         inc &   1       & \success{} & {\highlight{$ 724.35 (\stderr{  1.43}) $}} &   1       & \success{} & 3209.55 (\stderr{  1.41}) &  24       & 6029.36 (\stderr{  3.29}) & \success{} & 3416.38 (\stderr{ 62.46}) &   1      \\
        %         %
        %          &
        %         head &   0       & \success{} &  {\anotherhighlight{$69.62 (\stderr{  0.18})$}} &   1       & \success{} & {\newhighlight{$  49.11 (\stderr{  0.08}) $}} &   4       &  70.08 (\stderr{  0.09}) & \success{} & {\highlight{$  48.75 (\stderr{  0.21}) $}} &   1      \\
        %         %
        %          &
        %         tail &   0       & \success{} &  {\anotherhighlight{$87.12 (\stderr{  1.01})$}} &   1       & \success{} & {\newhighlight{$  61.43 (\stderr{  0.19}) $}} &   8       & 100.57 (\stderr{  0.33}) & \success{} & {\highlight{$  36.29 (\stderr{  0.11}) $}} &   1      \\
        %         %
        %          &
        %         last &   1       & \success{} & {\anotherhighlight{$1323.72 (\stderr{  1.17})$}} &   1       & \success{} & {\newhighlight{$ 1010.42 (\stderr{  0.81}) $}} &   4       & 1403.61 (\stderr{  1.19}) & \success{} & {\newnewhighlight{$ 921.10 (\stderr{  7.01}) $}} &   2      \\
        %         %
        %          &
        %         length &   1       & \success{} & 474.98 (\stderr{  0.64}) &   1       & \success{} & {\newhighlight{$ 304.31 (\stderr{  0.46}) $}} &   4       & 425.67 (\stderr{  0.67}) & \success{} & {\highlight{$ 306.96 (\stderr{  2.52}) $}} &   1      \\
        %         %
        %          &
        %         map &   1       & \success{} & {\highlight{$ 563.44 (\stderr{  0.80}) $}} &   0       & \success{} & 736.07 (\stderr{  1.08}) &   4       & 939.22 (\stderr{  1.09}) & \success{} & 739.58 (\stderr{  1.57}) &   1      \\
        %         %
        %          &
        %         replicate5 &   0       & \success{} & {\highlight{$ 382.76 (\stderr{  0.39}) $}} &   0       & \success{} & {\newhighlight{$ 379.05 (\stderr{  0.50}) $}} &   4       & 803.30 (\stderr{  0.96}) & \success{} & 387.55 (\stderr{  0.54}) &   1      \\
        %         %
        %          &
        %         replicate10 &   0       & \success{} & {\highlight{$ 2303.97 (\stderr{  3.57}) $}} &   0       & \success{} & 2399.01 (\stderr{100.22}) &   4       & 5184.56 (\stderr{102.21}) & \success{} & 2347.98 (\stderr{  4.21}) &   1      \\
        %         %
        %          &
        %         replicateN &   1       & \success{} & 608.43 (\stderr{  0.64}) &   1       & \success{} & {\newhighlight{$ 415.33 (\stderr{  0.35}) $}} &   4       & 507.33 (\stderr{  0.58}) & \success{} & {\highlight{$ 416.69 (\stderr{  1.12}) $}} &   1      \\
        %         %
        %          &
        %         stutter &   1       & \success{} & {\anotherhighlight{$1354.95 (\stderr{  0.96})$}} &   0       & \fail{} & Timeout & - & - & \success{} &  {\highlight{$15.14 (\stderr{  0.03})$}} &   0      \\
        %         %
        %          &
        %         sum &   2       & \success{} & {\highlight{$  86.59 (\stderr{  0.40}) $}} &   1       & \success{} & 2667.80 (\stderr{  4.89}) & 192       & 5764.73 (\stderr{  9.98}) & \success{} & 2715.72 (\stderr{  4.25}) &   2      \\
        %         %
        %         \hline \multirow{5}{*}{{\rotatebox{90}{\textbf{Stream}}}} &
        %         build &   0       & \success{} & {\highlight{$  63.30 (\stderr{  0.61}) $}} &   0       & \success{} & 105.76 (\stderr{  0.36}) &   4       & 189.25 (\stderr{  0.58}) & \success{} & 104.99 (\stderr{  0.28}) &   1      \\
        %         %
        %          &
        %         map &   1       & \success{} & {\highlight{$ 361.16 (\stderr{  1.45}) $}} &   0       & \success{} & 452.21 (\stderr{  0.66}) &   0       & 586.12 (\stderr{  0.77}) & \success{} & 862.39 (\stderr{  1.97}) &   1      \\
        %         %
        %          &
        %         take1 &   0       & \success{} &  {\anotherhighlight{$35.16 (\stderr{  0.13})$}} &   0       & \success{} & {\highlight{$  25.52 (\stderr{  0.07}) $}} &   0       &  45.23 (\stderr{  0.07}) & \success{} &  25.60 (\stderr{  0.08}) &   1      \\
        %         %
        %          &
        %         take2 &   0       & \success{} & {\highlight{$ 112.80 (\stderr{  0.23}) $}} &   0       & \success{} & 165.75 (\stderr{  0.24}) &   0       & 254.58 (\stderr{  0.46}) & \success{} & 169.80 (\stderr{  0.26}) &   1      \\
        %         %
        %          &
        %         take3 &   0       & \success{} & {\highlight{$ 931.72 (\stderr{  0.96}) $}} &   0       & \success{} & 1567.68 (\stderr{  1.52}) &   0       & 2193.77 (\stderr{  2.42}) & \success{} & 1591.96 (\stderr{  1.60}) &   1      \\
        %         %
        %         \hline \multirow{5}{*}{{\rotatebox{90}{\textbf{Bool}}}} &
        %         neg &   0       & \success{} & {\anotherhighlight{$ 213.97 (\stderr{  0.36})$}} &   2       & \success{} & {\highlight{$ 176.02 (\stderr{  0.23}) $}} &   0       & 346.55 (\stderr{  0.72}) & \success{} & 180.38 (\stderr{  1.51}) &   2      \\
        %         %
        %          &
        %         and &   0       & \success{} & {\anotherhighlight{$ 3178.44 (\stderr{  1.29})$}} &   4       & \fail{} & Timeout & - & - & \success{} & {\highlight{$ 1706.81 (\stderr{  4.23}) $}} &   4      \\
        %         %
        %          &
        %         impl &   0       & \success{} & {\anotherhighlight{$ 1754.02 (\stderr{  2.31})$}} &   4       & \fail{} & Timeout & - & - & \success{} & {\highlight{$ 541.16 (\stderr{  1.19})$}} &   4      \\
        %         %
        %          &
        %         or &   0       & \success{} & {\anotherhighlight{$ 1231.19 (\stderr{  1.84})$}} &   4       & \fail{} & Timeout & - & - & \success{} & {\highlight{$ 307.74 (\stderr{  0.32}) $}} &   4      \\
        %         %
        %          &
        %         xor &   0       & \success{} & {\highlight{$ 2897.35 (\stderr{  2.18}) $}} &   4       & \fail{} & Timeout & - & - & \success{} & 9202.67 (\stderr{  3.98}) &   4      \\
        %         %
        %         \hline \multirow{7}{*}{{\rotatebox{90}{\textbf{Maybe}}}} &
        %         bind &   0       & \success{} & {\anotherhighlight{$ 162.79 (\stderr{  0.34})$}} &   0       & \success{} & 121.40 (\stderr{  0.54}) &   0       & 172.47 (\stderr{  0.58}) & \success{} & {\newnewhighlight{$ 120.15 (\stderr{  0.20}) $}} &   1      \\
        %         %
        %          &
        %         fromMaybe &   0       & \success{} &  55.36 (\stderr{  0.12}) &   0       & \success{} &  39.18 (\stderr{  0.16}) &   0       &  49.78 (\stderr{  0.31}) & \success{} & {\newnewhighlight{$  39.11 (\stderr{  0.06}) $}} &   2      \\
        %         %
        %          &
        %         return &   0       & \success{} &  {\anotherhighlight{$10.09 (\stderr{  0.05})$}} &   0       & \success{} &  10.89 (\stderr{  0.40}) &   4       &  22.75 (\stderr{  0.83}) & \success{} & {\highlight{$   5.29 (\stderr{  0.10}) $}} &   0      \\
        %         %
        %          &
        %         isJust &   0       & \success{} &  {\anotherhighlight{$70.58 (\stderr{  0.11})$}} &   2       & \success{} &  56.84 (\stderr{  1.43}) &   0       &  79.52 (\stderr{  2.13}) & \success{} & {\highlight{$  52.64 (\stderr{  0.49}) $}} &   2      \\
        %         %
        %          &
        %         isNothing &   0       & \success{} & {\anotherhighlight{$103.97 (\stderr{  0.28})$}} &   2       & \success{} &  82.79 (\stderr{  2.73}) &   0       & 114.10 (\stderr{  3.71}) & \success{} & {\highlight{$  77.92 (\stderr{  0.10}) $}} &   2      \\
        %         %
        %          &
        %         map &   0       & \success{} &  {\anotherhighlight{$56.17 (\stderr{  0.16})$}} &   0       & \success{} & {\highlight{$  39.57 (\stderr{  0.08}) $}} &   0       &  60.04 (\stderr{  0.16}) & \success{} &  40.18 (\stderr{  0.52}) &   1      \\
        %         %
        %          &
        %         mplus &   0       & \success{} & 323.95 (\stderr{  0.38}) &   1       & \success{} & {\highlight{$ 187.30 (\stderr{  0.57}) $}} &   0       & 252.95 (\stderr{  0.57}) & \success{} & 188.87 (\stderr{  1.13}) &   1      \\
        %         %
        %         \hline \multirow{4}{*}{{\rotatebox{90}{\textbf{Nat}}}} &
        %         isEven &   1       & \success{} & {\anotherhighlight{$1041.21 (\stderr{  1.07})$}} &   2       & \success{} & {\newhighlight{$ 1027.42 (\stderr{ 12.34}) $}} &   8       & 1351.11 (\stderr{ 16.70}) & \success{} & {\highlight{$ 981.20 (\stderr{  1.78}) $}} &   2      \\
        %         %
        %          &
        %         pred &   0       & \success{} &  {\anotherhighlight{$ 50.63 (\stderr{  0.26})$}} &   1       & \success{} &  66.93 (\stderr{  1.90}) &   8       & 120.55 (\stderr{  4.25}) & \success{} & {\highlight{$  38.27 (\stderr{  1.49}) $}} &   1      \\
        %         %
        %          &
        %         succ &   0       & \success{} & {\highlight{$ 117.53 (\stderr{  0.19}) $}} &   1       & \success{} & 189.67 (\stderr{  3.25}) &   8       & 361.33 (\stderr{  5.81}) & \success{} & 179.54 (\stderr{  0.89}) &   1      \\
        %         %
        %          &
        %         sum &   1       & \success{} & {\highlight{$ 1596.32 (\stderr{  1.22}) $}} &   1       & \success{} & 2438.60 (\stderr{ 20.95}) &  12       & 3177.10 (\stderr{ 30.93}) & \success{} & 2705.51 (\stderr{  2.89}) &   3      \\
        %         %
        %         \hline \multirow{3}{*}{{\rotatebox{90}{\textbf{Tree}}}} &
        %         map &   1       & \success{} & {\anotherhighlight{$1183.14 (\stderr{  1.66})$}} &   0       & \success{} & 1643.18 (\stderr{  7.83}) &   4       & 2097.70 (\stderr{ 12.95}) & \success{} & {\newnewhighlight{$ 1063.38 (\stderr{  1.11}) $}} &   1      \\
        %         %
        %          &
        %         stutter &   1       & \success{} & {\anotherhighlight{$703.27 (\stderr{  0.53})$}} &   0       & \success{} & 1065.97 (\stderr{ 10.64}) &   4       & 1275.54 (\stderr{ 15.49}) & \success{} & {\newnewhighlight{$ 664.37 (\stderr{  1.45}) $}} &   1      \\
        %         %
        %          &
        %         sum &   2       & \success{} & {\highlight{$ 1499.00 (\stderr{  1.31}) $}} &   3       & \success{} & 2787.05 (\stderr{ 28.36}) & 192       & 6229.86 (\stderr{ 69.85}) & \success{} & 2675.69 (\stderr{ 11.44}) &   3      \\
        %         %
        %         \hline \multirow{3}{*}{{\rotatebox{90}{\textbf{Misc}}}} &
        %         compose &   0       & \success{} &  {\anotherhighlight{$40.82 (\stderr{  0.23})$}} &   0       & \success{} &  40.93 (\stderr{  0.82}) &   2       &  55.28 (\stderr{  0.95}) & \success{} & {\highlight{$  39.27 (\stderr{  0.13}) $}} &   0      \\
        %         %
        %          &
        %         copy &   0       & \success{} &   {\anotherhighlight{$5.42 (\stderr{  0.04})$}} &   0       & \success{} & {\newhighlight{$   5.38 (\stderr{  0.16}) $}} &   2       &  11.70 (\stderr{  0.36}) & \success{} & {\highlight{$   5.38 (\stderr{  0.15}) $}} &   0      \\
        %         %
        %          &
        %         push &   0       & \success{} & {\highlight{$  26.87 (\stderr{  0.14}) $}} &   0       & \success{} &  27.75 (\stderr{  0.86}) &   2       &  42.14 (\stderr{  1.28}) & \success{} &  27.03 (\stderr{  0.99}) &   0      \\
        %         %
        %         \end{tabular}}
        %         \end{center}}}
        %         \caption{Results. $\mu{T}$ in \emph{ms} to 2 d.p. with standard sample error in brackets}
        %         \label{tab:results}
        %         \vspace{-2.5em}
        %         \end{table}

        \begin{table}[H]
                {\footnotesize{
                \begin{center}
                \setlength{\tabcolsep}{0.3em}
                \scalebox{0.9}{
                \begin{tabular}{p{1.25em}ccl|p{0.75em}rc|p{0.75em}rcc} & & & &
                \multicolumn{3}{c|}{Graded}&\multicolumn{4}{c|}{Cartesian + Graded type-check} \\ \hline \multicolumn{2}{c}{{Problem}}& \multicolumn{1}{c}{{Ctxt}} & \multicolumn{1}{l|}{{\#/Exs.}} & & \multicolumn{1}{c}{$\mu{T}$ (ms)} & \multicolumn{1}{c|}{{Paths}} & & \multicolumn{1}{c}{$\mu{T}$ (ms)} & \multicolumn{1}{c}{\textsc{N}} & \multicolumn{1}{c|}{{Paths}} \\ \hline
                \hline \multirow{19}{*}{{\rotatebox{90}{\textbf{List}}}} &
                append &   0       &   0 (+1)        & \success{} & 115.35 (\stderr{  5.13}) & 130       & \success{} & {\highlight{$ 105.24 (\stderr{  0.36}) $}} &   8      & 130      \\
                %
                 &
                concat &   1       &   0 (+3)        & \success{} &  1104.76 (\stderr{  1.60})  & 1354       & \success{} & {\highlight{$ 615.29 (\stderr{  1.43}) $}} &  12      &1354      \\
                %
                 &
                empty &   0       &   0        & \success{} &   5.31 (\stderr{  0.02}) &  17       & \success{} & {\highlight{$   1.20 (\stderr{  0.01}) $}} &   0      & 17      \\
                %
                 &
                snoc &   1       &   1       & \success{} & 2137.28 (\stderr{  2.14}) & {\newhighlight{$2204$}}       & \success{} & {\highlight{$ 1094.03 (\stderr{  4.75}) $}} &   8      &2278      \\
                %
                 &
                drop &   1       &   1        & \success{} & 1185.03 (\stderr{  2.53})  &  {\newhighlight{$1634$}}       & \success{} & {\highlight{$ 445.95 (\stderr{  1.71}) $}} &   8      &1907      \\
                %
                 &
                flatten &   2       &   1       & \success{} & 1369.90 (\stderr{  2.60})  & 482       & \success{} & {\highlight{$ 527.64 (\stderr{  1.04}) $}} &   8      &482      \\
                %
                 &
                bind &   2       &   0  (+2)    &  \success{} & {\highlight{$  62.20 (\stderr{  0.21}) $}} &  {\newhighlight{$129$}}       & \success{} & 622.84 (\stderr{  0.95}) &  18      &427      \\
                %
                 &
                return &   0       &   0 (+1)       & \success{} & {\highlight{$  19.71 (\stderr{  0.18}) $}} &  49       & \success{} &  22.00 (\stderr{  0.08})  &   4      & 49      \\
                %
                 &
                inc &   1       &   1       &  \success{} & {\highlight{$ 708.23 (\stderr{  0.69}) $}} & {\newhighlight{$879$}}       & \success{} &  2835.53 (\stderr{  7.69}) &  24      &1664      \\
                %
                 &
                head &   0       &   1        & \success{} & 68.23 (\stderr{  0.53})  &  34       & \success{} & {\highlight{$  20.78 (\stderr{  0.10}) $}} &   4      & 34      \\

                 &
                tail &   0       &   1        & \success{} &  84.23 (\stderr{  0.20}) &  33       & \success{} & {\highlight{$  38.59 (\stderr{  0.06}) $}} &   8      & 33      \\
                %
                 &
                last &   1       &   1 (+1)        & \success{} & 1298.52 (\stderr{  1.17}) & {\newhighlight{$ 593 $}}      & \success{} & {\highlight{$ 410.60 (\stderr{  6.25}) $}} &   4      &684      \\
                %
                 &
                length &   1       &   1        & \success{} &  464.12 (\stderr{  0.90})  & 251       & \success{} & {\highlight{$ 127.91 (\stderr{  0.58}) $}} &   4      &251      \\
                %
                 &
                map &   1       &   0 (+1)       &  \success{} &  550.10 (\stderr{  0.61})  & 3075       & \success{} & {\highlight{$ 249.42 (\stderr{  0.73}) $}} &   4      &3075      \\
                %
                 &
                replicate5 &   0       &   0 (+1)       & \success{} & {\highlight{$ 372.23 (\stderr{  0.70}) $}} & 1295       & \success{} & 435.78 (\stderr{  1.06}) &   4      &1295      \\
                %
                 &
                replicate10 &   0       &   0  (+1)      & \success{} & {\highlight{$ 2241.87 (\stderr{  4.74}) $}} & 10773       & \success{} &  2898.93 (\stderr{  1.47}) &   4      &10773      \\
                %
                 &
                replicateN &   1       &   1        & \success{} & 593.86 (\stderr{  1.68})  & 772       & \success{} & {\highlight{$ 108.98 (\stderr{  0.65}) $}} &   4      &772      \\
                %
                 &
                stutter &   1       &   0       &  \success{} & {\highlight{$ 1325.36 (\stderr{  1.77}) $}} & {\newhighlight{$1792$}}       & \fail{} & Timeout & - & -\\
                %
                 &
                sum &   2       &   1 (+1)      &  \success{} & {\highlight{$  84.09 (\stderr{  0.25}) $}} & {\newhighlight{$ 208 $}}      & \success{} & 3236.74 (\stderr{  0.87}) & 192      &3623      \\
                %
                \hline \multirow{5}{*}{{\rotatebox{90}{\textbf{Stream}}}} &
                build &   0       &   0  (+1)     & \success{} & {\highlight{$  61.27 (\stderr{  0.45}) $}} &  75       & \success{} &  84.44 (\stderr{  0.49}) &   4      & 75      \\
                %
                 &
                map &   1       &   0  (+1)      & \success{} & 351.93 (\stderr{  0.91}) & 1363       & \success{} & {\highlight{$ 153.01 (\stderr{  0.37}) $}} &   0      &1363      \\
                %
                 &
                take1 &   0       &   0    (+1)    & \success{} &  34.02 (\stderr{  0.23}) &  22       & \success{} & {\highlight{$  19.32 (\stderr{  0.05}) $}} &   0      & 22      \\
                %
                 &
                take2 &   0       &   0  (+1)     &  \success{} & 110.18 (\stderr{  0.31}) & {\newhighlight{$ 204$}}       & \success{} & {\highlight{$  89.10 (\stderr{  0.18}) $}} &   0      &208      \\
                %
                 &
                take3 &   0       &   0  (+1)     &  \success{} & 915.39 (\stderr{  1.42}) & {\newhighlight{$ 1139 $}}      & \success{} & {\highlight{$ 631.47 (\stderr{  1.14}) $}} &   0      &1172      \\
                %
                \hline \multirow{5}{*}{{\rotatebox{90}{\textbf{Bool}}}} &
                neg &   0       &   2       &  \success{} & 209.09 (\stderr{  0.31}) &  42       & \success{} & {\highlight{$ 168.37 (\stderr{  0.56}) $}} &   0      & 42      \\
                %
                 &
                and &   0       &   4       &  \success{} & {\highlight{$3129.30 (\stderr{  2.82})$}} & {\newhighlight{$ 786$}}       & \success{} & 7069.14 (\stderr{ 15.91}) &   0      &2153      \\
                %
                 &
                impl &   0       &   4       &   \success{} & {\highlight{$1735.09 (\stderr{  4.31})$}} & {\newhighlight{$ 484$}}       & \success{} & 3000.48 (\stderr{  4.65}) &   0      &1214      \\
                %
                 &
                or &   0       &   4       &   \success{} & {\highlight{$1213.86 (\stderr{  1.02})$}} &  {\newhighlight{$374 $}}      & \success{} &  2867.74 (\stderr{  3.52})  &   0      &1203      \\
                %
                 &
                xor &   0       &   4       &   \success{} & {\highlight{$2865.79 (\stderr{  4.33})$}} &  {\newhighlight{$736$}}       & \success{} & 7251.38 (\stderr{ 32.06}) &   0      &2229      \\
                %
                \hline \multirow{7}{*}{{\rotatebox{90}{\textbf{Maybe}}}} &
                bind &   0       &   0 (+1)      &   \success{} & 159.87 (\stderr{  0.52}) & 237       & \success{} & {\highlight{$  55.33 (\stderr{  0.33}) $}} &   0      &237      \\
                %
                 &
                fromMaybe &   0       &   0 (+2)        & \success{} &  54.27 (\stderr{  0.35}) &  18       & \success{} & {\highlight{$  11.58 (\stderr{  0.10}) $}} &   0      & 18      \\
                %
                 &
                return &   0       &   0        & \success{} & {\highlight{$   9.89 (\stderr{  0.02}) $}} &  17       & \success{} &  11.49 (\stderr{  0.04}) &   4      & 17      \\
                %
                 &
                isJust &   0       &   2        & \success{} &  69.33 (\stderr{  0.17}) &  48       & \success{} & {\highlight{$  22.07 (\stderr{  0.09}) $}} &   0      & 48      \\
                %
                 &
                isNothing &   0       &   2         & \success{} & 102.42 (\stderr{  0.32}) &  49       & \success{} & {\highlight{$  31.89 (\stderr{  0.22}) $}} &   0      & 49      \\
                %
                 &
                map &   0       &   0  (+1)     &   \success{} &  54.90 (\stderr{  0.22}) & 120       & \success{} & {\highlight{$  22.01 (\stderr{  0.10}) $}} &   0      &120      \\
                %
                 &
                mplus &   0       &   1       &   \success{} & 319.64 (\stderr{  0.47}) & 318       & \success{} & {\highlight{$  70.98 (\stderr{  0.05}) $}} &   0      &318      \\
                %
                \hline \multirow{4}{*}{{\rotatebox{90}{\textbf{Nat}}}} &
                isEven &   1       &   2       &  \success{} & 1027.79 (\stderr{  1.28}) & {\newhighlight{$466$}}       & \success{} & {\highlight{$ 313.77 (\stderr{  0.92}) $}} &   8      &468      \\
                %
                 &
                pred &   0       &   1       &  \success{} & {\highlight{$  46.20 (\stderr{  0.18}) $}} &  33       & \success{} & 48.04 (\stderr{  0.13}) &   8      & 33      \\
                %
                 &
                succ &   0       &   1       &   \success{} & {\highlight{$ 115.16 (\stderr{  0.91}) $}} &  76       & \success{} &  156.02 (\stderr{  0.50}) &   8      & 76      \\
                %
                 &
                sum &   1       &   1 (+2)      &   \success{} & 1582.23 (\stderr{  3.60})  & 751       & \success{} & {\highlight{$ 734.38 (\stderr{  1.41}) $}} &  12      &751      \\
                %
                \hline \multirow{3}{*}{{\rotatebox{90}{\textbf{Tree}}}} &
                map &   1       &   0 (+1)      &   \success{} &  1168.60 (\stderr{  1.21}) & 4259       & \success{} & {\highlight{$ 525.47 (\stderr{  1.31}) $}} &   4      &4259      \\
                %
                 &
                stutter &   1       &   0  (+1)       & \success{} &  693.44 (\stderr{  1.21}) & 832       & \success{} & {\highlight{$ 219.91 (\stderr{  1.02}) $}} &   4      & {\newhighlight{$674$}}      \\
                %
                 &
                sum &   2       &   3       &  \success{} & {\highlight{$ 1477.83 (\stderr{  1.28}) $}} &  {\newhighlight{$3230 $}}      & \success{} & 3532.24 (\stderr{  7.19}) & 192      &3623      \\
                %
                \hline \multirow{3}{*}{{\rotatebox{90}{\textbf{Misc}}}} &
                compose &   0       &   0         & \success{} & 40.27 (\stderr{  0.08}) &  38       & \success{} & {\highlight{$  14.53 (\stderr{  0.09}) $}} &   2      & 38      \\
                %
                 &
                copy &   0       &   0       &  \success{} & {\highlight{$   5.24 (\stderr{  0.04}) $}} &  21       & \success{} &  6.16 (\stderr{  0.10}) &   2      & 21      \\
                %
                 &
                push &   0       &   0       &   \success{} &  26.66 (\stderr{  0.18}) &  45       & \success{} & {\highlight{$  14.23 (\stderr{  0.13}) $}} &   2      & 45      \\
                %
                \end{tabular}}
                \end{center}}}
                \caption{Results. $\mu{T}$ in \emph{ms} to 2 d.p. with standard sample error in brackets}
                \label{tab:results-graded}
                \vspace{-2.5em}
                \end{table}




% \iffalse
% The first results column (Graded) contains the results for graded synthesis,
% including the number of examples needed (\#/Exs).
% The second results column (Cartesian - Consulting) contains the results for synthesising a
% program in the Cartesian (de-graded) setting, using the
% same examples set as the Graded column, recording the number of
% retries (consultations of the oracle) \textsc{N}
% and $(\mu{}T + \text{OracleT})$ records the total synthesis
% time plus the time taken by the Oracle to type-check potential solutions against the
% original graded type.
% The third results column (Cartesian - Examples) contains the results for
% synthesising from the de-graded type but without allowing retries from
% the oracle. Instead, additional input-output examples are supplied
% to provide a strong
% specification such that no retries are needed. As with the Graded column, the number of
% input-output examples used is recorded.

% For each row, we then highlight the column which synthesised a result the fastest in
% $\highlight{\text{blue}}$ (taking into account OracleT). We highlight
% in $\newhighlight{\text{pink}}$ the results in the Cartesian setting which were
% synthesised faster than the Graded without the inclusion of OracleT. If the Graded result was
% faster than the Cartesian (with consulting)'s OracleT time, but was outperformed by Cartesian (Examples),
% then we highlight this result in $\anotherhighlight{\text{purple}}$.

% Finally, in the Cartesian (Examples) column,
% we highlight results which were synthesised faster than the Graded but which required more input-output examples in
% $\newnewhighlight{\text{yellow}}$.

% When comparing the Graded column to the Cartesian (with consulting) column,
% the results show that in $41$ of the $46$ benchmarks (89\%) the graded
% approach out-performed non-graded synthesis when taking into account
% the modest penalty for consulting the oracle (the sum of the $\highlight{\text{blue}}$ and $\anotherhighlight{\text{purple}}$ results in the Graded column).
% Ignoring the oracle, for $36$ of the $46$ benchmarks (78\%) the graded approach still out-performed
% the Cartesian with consulting.


% We also find that for the non-graded setting without consulting the oracle --- the Cartesian (with examples) column, further examples
% are required to synthesise the same program as the graded in $20$ out of $46$ (43\%) cases. In these cases, an average of
% $1.25$ additional examples was required, with $5$ of these benchmarks synthesising a result faster than the graded equivalent.
% The difference in speed between Graded and Cartesian (with examples) is
% less stark than Graded and Cartesian (with consulting), with the graded approach faster in 22 out of 46 benchmarks (48\%).
% \fi


We briefly examine some of the more complex benchmarks which make use
of almost all of our synthesis rules in one program. The
\granin{stutter} case from the List class of benchmarks is specified as:
%
\begin{granule}
stutter : forall a . List (a [2]) %1..$\infty$ -> List a
spec
    stutter % 0..$\infty$
stutter = ?
\end{granule}
%
This is a function which takes a list of values of type \granin{a}, where each
element in the list is explicitly graded by \granin{2}, indicating that each
element must be used twice. The return type of \granin{stutter} is a list of
type \granin{a}. The argument list itself must be used at least once with
potential usage extending up to infinity, suggesting that some recursion will be
necessary in the program. This is further emphasised by the \granin{spec}, which
states that we can use the definition of \granin{stutter} inside the function
body in an unrestricted way. From this, we synthesise:
%
\begin{granule}
stutter Nil = Nil;
stutter (Cons [u] z) = (Cons u) ((Cons u) (stutter z))
\end{granule}
%
in 1325ms ($\sim$1.3 seconds).
We also have a \granin{stutter} case in the Tree class of benchmarks, which instead performs
the above transformation over a binary tree data type, which yields the following program
in 693ms ($\sim$0.7 seconds):
\begin{granule}
stutter : forall a b . Tree (a [2]) % 1..$\infty$ -> Tree (a, a)
spec
    stutter %0..$\infty$
stutter Leaf = Leaf;
stutter (Node y [v] u) = ((Node (stutter y)) (v, v)) (stutter u)
\end{granule}
%
Lastly, we compare between the number of examples required by Granule (using grades)
and the \textsc{Myth} program synthesis tool (based on pruning by examples).
We take the cases from our benchmark set which have an equivalent in the \textsc{Myth} benchmark suite~\citep{oseraMYTH1}.
Table \ref{tab:example-comp} shows the number of examples used in Granule,
and the number required for the equivalent \textsc{Myth} case. In both Granule and \textsc{Myth} this number represents
the minimal number of examples required to synthesise the correct program.

\begin{table}[h]
\begin{center}
\setlength{\tabcolsep}{0.3em}
\scalebox{.95}{
\begin{tabular}{p{2.25em}c|c|c} & &
\multicolumn{1}{c|}{Granule}&\multicolumn{1}{c}{\textsc{Myth}}\\ \hline
\multicolumn{2}{c|}{{Problem}} & \multicolumn{1}{c}{\#/Exs} & \multicolumn{1}{c}{\#/Exs} \\ \hline
\hline \multirow{12}{*}{{\rotatebox{0}{\textbf{List}}}}
& append & 0 & 6 \\
& concat & 1 & 6 \\
& snoc & 1 & 8 \\
& drop & 1 & 13 \\
& inc & 1 & 4 \\
& head & 1 & 3 \\
& tail & 1 & 3 \\
& last & 1 & 6 \\
& length & 1 & 3 \\
& map  & 0 & 8 \\
& stutter & 0 & 3 \\
& sum & 1 & 3 \\
\hline \multirow{5}{*}{{\rotatebox{0}{\textbf{Bool}}}}
& neg & 2 & 2 \\
& and & 4  & 4 \\
& impl &4  & 4 \\
& or & 4 & 4 \\
& xor & 4 & 4 \\
\hline \multirow{2}{*}{{\rotatebox{0}{\textbf{Nat}}}}
& isEven & 2 & 4 \\
& pred & 1 & 3 \\
\hline \multirow{1}{*}{{\rotatebox{0}{\textbf{Tree}}}}
& map & 0 & 7 \\ \\ \\ \\ \\
\end{tabular}}
\end{center}
\vspace{0.5em}
\caption{Number of examples needed for synthesis, comparing Granule vs. \textsc{Myth}}
\label{tab:example-comp}
\end{table}


For most of the problems (15 out of 20), Granule required fewer examples to identify the desired
program in synthesis. The disparity in the number of examples required is quite significant in some cases: with
13 examples required by \textsc{Myth} to synthesise the \emph{concat} problem but only 1 example for
Granule. This shows the pruning power of graded information in synthesis, confirming H2.


\section{Synthesis of Linear Haskell Programs}
\label{sec:linear-haskell}

As part of a growing trend of resourceful types being added to more mainstream
languages, Haskell has introduced support for linear types as of GHC 9, using an
underlying graded type system which can be enabled as a language extension of
GHC's existing type system~\citep{DBLP:journals/pacmpl/BernardyBNJS18} (the
\haskin{LinearType} extension). This system is closely related to Granule, but
limited only to one semiring for its grades. This however presents an exciting
opportunity: can we leverage our tool to synthesise (linear) Haskell programs?

Like Granule, grades in Linear Haskell can be expressed as ``multiplicities'' on
function types: \haskin{a \%r -> b}. The multiplicity $r$ can be either $1$ or
$\omega$ (or polymorphic), with $1$ denoting linear usage (also written as
\haskin{'One}) and $\omega$ for (\haskin{'Many}) unrestricted usage. Likewise,
in Granule, we can model linear types using the $0$-$1$-$\omega$ semiring
\citep{hughes:lirmm-03271465}.

Synthesising Linear Haskell programs then simply becomes a task of parsing a
Haskell type into a Granule equivalent, synthesising a term from this, and
compiling the synthesised term back into Haskell. The close syntactic
correspondence between Granule and Haskell makes this translation
straightforward.

Our implementation includes a prototype synthesis tool using this approach. A
synthesis problem takes the form of a Linear Haskell program with a hole, e.g.
\begin{haskell}
{-# LANGUAGE LinearTypes #-}
swap :: (a, b) %One -> (b, a)
swap = _
\end{haskell}
We invoke the tool with \haskin{gr --linear-haskell swap.hs} producing:
\begin{haskell}
swap (z, y) = (y, z)
\end{haskell}
%
Haskell tuples are converted into a Granule data type, generated based on the
tuple's arity. This data type is given unique name based on this size, e.g.
\granin{,4} for a tuple of arity 4. Using the special character \granin{,} in
the constructor name prevents name clashes with other in-scope data
constructors, as this character would not be permitted in a typical user-defined
constructor. 

Users may make use of lists, tuples, \haskin{Maybe} and \haskin{Either} data
types from Haskell's prelude, as well as user-defined ADTs. Further integration
of the tool, as well as support for additional Haskell features such as GADTs is
left as future work.

This tool can be especially useful as a programming aid when writing linear
versions of Haskell libraries. To conclude this section, we showcase some of the
programs synthesised via our Linear Haskell tool with the goal of writing a
Linear Haskell library for Haskell's \haskin{Maybe} data type. 

\vspace{1em}
\begin{haskell}
{-# LANGUAGE LinearTypes #-}

maybe :: b %Many -> (a %One -> b) %Many -> (Maybe a) %One -> b
maybe x y Nothing = x
maybe x y (Just u) = y u

bind :: Maybe a %One -> (a %One -> Maybe b) %Many -> Maybe b
bind Nothing y = Nothing
bind (Just z) y = y z

map :: (a %One -> b) %Many -> Maybe a %One -> Maybe b
map x Nothing = Nothing
map x (Just z) = Just (x z)

maybeToList :: Maybe a %One -> [a]
maybeToList Nothing = []
maybeToList (Just y) = [y]

fromMaybe :: Maybe a %One -> a %Many -> a
fromMaybe Nothing y = y
fromMaybe (Just z) y = z

\end{haskell}


\section{Conclusion}
\label{section:graded-base-conclusion}

In this chapter we presented a synthesis calculus for a feature-rich type system
based on the fully graded $\lambda$-calculus of section~\ref{sec:graded-base},
which complements our graded linear system of Chapter~\ref{chapter:core} to
allow us to synthesise programs for the major approaches to graded type systems.
We found through our experimental evaluation that synthesising programs in this
calculus requires the exploration of fewer synthesis paths when using the
information provided by grades to prune the search space of candidate programs.
In terms of pure speed, un-graded type-directed program synthesis outperformed
our implementation, largely due to the overhead of discharging constraints to an
SMT solver. 

This discrepancy in speed necessitates that our synthesis tool seek a more
efficient means of interfacing with the solver. However, the theoretical
advantage of grade-based pruning remains clear: the search space was the same or
reduced in all but one of our benchmarking examples in
Table~\ref{tab:results-graded}. In the next chapter, we conclude our synthesis
journey with some future directions that this work might take, including how to
improve interaction with the solver. 



% Emphasise point about fewer paths 
