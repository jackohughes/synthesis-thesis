\chapter{Background}
\label{chapter:background}
Before diving straight into designing program synthesis calculi, we first need
to formally define our target languages. We take
this chapter as an opportunity to do so, and to examine more closely some
of the properties of these linear and graded systems. 

Since \citet{girard1987linear}'s original work on Linear Logic, the development
of type systems which convey additional information about the program's
structure has evolved into a distinct paradigm, culminating in recent years with
the notion of \textit{graded types}. Approaches to graded type systems run the
gamut, incorporating a wide range of \emph{effect} and \emph{coeffect} systems,
however, they can typically be distilled into two categories, with distinct
lineages: 
\begin{itemize}
  \item Systems where a graded modal type operator introduces and eliminates
        graded modalities above some existing type system. This is the default
        approach of Granule, where the underlying type system is linear, and
        grade modalities are introduced and eliminated via a family of $\Box$
        modal type operators. We refer to these as ``graded linear'' or ``linear
        base'' systems.
  \item Systems where grades permeate the program, and are introduced via
        annotations on function arrows. These systems do away with the
        underlying linear basis that typifies the former category of systems.
        This is the approach taken by Linear
        Haskell~\citep{DBLP:journals/pacmpl/BernardyBNJS18}, where grades (or
        ``multiplicities'') are specified using the \granin{\%} operator. We
        refer to these as ``fully graded'' or ``graded base'' systems.
\end{itemize}  
These two different styles to graded types mirror the dual development of effect
systems and graded monadic systems in the literature
(see~\citet{10.1145/601775.601776}). In the latter case, the two were eventually
found to be equivalent, while the same treatment for the former remains ongoing
work. 

\paragraph{Roadmap} The remainder of this chapter formally defines these
calculi, starting with the linear $\lambda$-calculus in
Section~\ref{sec:linear-lambda-calc}. Following this, in
Section~\ref{sec:graded-linear} we extend the linear $\lambda$-calculus with a
graded modal type (Section~\ref{sec:linear-base}) before presenting the fully
graded $\lambda$-calculus (Section~\ref{sec:graded-base}). In
Section~\ref{sec:op-sem} we briefly provide a call-by-name operational semantics
for our calculi, and note that substitution is admissible in each. Finally
outlining our approach to how we use these calculi in synthesis in
Section~\ref{sec:two-typing}. Throughout, we include examples of programs
typeable in their respective calculi as Granule code, providing a gentle
introduction to Granule syntax. 

\section{Terminology}
Throughout this thesis we will tend towards using a \textit{types-and-programs}
terminology rather than \textit{propositions-and-proofs}. Via the Curry-Howard
correspondence, one can switch smoothly to viewing our approach to program
synthesis as proof search in logic.

The functional programming languages we discuss are presented as typed
calculi given by sets of \textit{types}, \textit{terms} (programs), and \textit{typing
 rules} that relate a term to its type. The most well-known typed
calculus is the simply-typed $\lambda$-calculus (STLC), which corresponds to
the implication fragment of intuitionistic logic. We assume familiarity with STLC, and 
use this to facilitate our explanation of linear and graded types.

A \textit{judgment} defines the typing relation between a type and a term based on a
\textit{context}. In STLC, judgments have the
form: $\Gamma \vdash t : A$, stating that under some context of
\textit{assumptions} $\Gamma$ the program term $t$ can be assigned the type $A$.
An assumption is a name with an associated type, written $x : A$ and
corresponds to an in-scope variable in a program.

A term can be related to a type if we can derive a valid judgment through the
application of typing rules. The application of these rules forms a tree
structure known as a \textit{typing derivation}.

\section{Linear and Substructural Logics}
Linear logic allows one to be more descriptive about the properties of a
derivation in intuitionistic logic. In type systems such as STLC, the properties
of \textit{weakening}, \textit{contraction}, and \textit{exchange} are assumed
implicitly. These are typing rules which are \textit{structural} as they
determine how the context may be used rather than being directed by the syntax.
Weakening is a rule which allows terms that are not needed in a typing
derivation to be discarded. Contraction works as a dual to weakening, allowing
an assumption in the context to be used more than once. Finally, exchange allows
assumptions in a context to arbitrarily re-ordered. The rules themselves are
provided by Figure~\ref{fig:substructural}.

\begin{figure}[H]
  \begin{gather*}
  \begin{array}{c}
    \inferrule*[right=Weakening]{\Gamma \vdash t : B}{\Gamma, x : A \vdash t : B}
    \;\;\;\;
    \inferrule*[right=Contraction]{\Gamma, x : A, y : A \vdash t : B}{\Gamma, x : A \vdash [x/y] t : B}
    \\[0.9em]
    \inferrule*[right=Exchange]{\Gamma_{1}, y : B, x : A, \Gamma_{2} \vdash t : C} {\Gamma_{1}, x : A, y : B, \Gamma_{2} \vdash t : C}
    \end{array}
  \end{gather*}
  \caption{Substructural rules for weakening, contraction, and exchange}
  \label{fig:substructural}
\end{figure}

Linear logic is thus known as a \textit{substructural} logic because it lacks
the weakening and contraction rules, while permitting exchange. The exclusion
and inadmissibility of these rules means that in order to construct a typing
derivation, each assumption must be used exactly once: arbitrarily copying or
discarding hypotheses is disallowed, excluding a vast number of programs from being
typeable. 

As one can imagine, the different combinations of permitted structural rules
yields various other substructural logics. Affine logic permits
exchange and weakening, but disallows contraction, resulting in system where
values may be used \emph{at most}  once. Relevant logic only disallows
weakening (hypotheses can be used \emph{at least} once), while Ordered logic disallows all
three (hypotheses must be used exactly once and in order).

\subsection{The Linear $\lambda$-Calculus}
\label{sec:linear-lambda-calc}
Our focus is on the implication fragment of linear logic. By permitting only the
exchange structural rule, we can integrate linear logic into STLC, yielding a
\emph{linear} $\lambda-$calculus. This provides us with a foundation for
programming with substructural logics, which we will later refine with graded
types. 

The types of the linear $\lambda$-calculus are given by the grammar: 
\begin{align*}
  \hspace{-0.9em}[[ A ]] , [[ B ]] & ::=
         [[ A ]] \multimap [[ B ]]
  {\small{\tag{types}}}
\end{align*}
Like STLC, we have one type former: the function type. Here, however, our function type
is a \emph{linear} function arrow (denoted by $\multimap$).

%\footnote{Although
%Granule code uses $\rightarrow$ syntax rather than $\multimap$ for linear
%functions for the sake of familiarity with standard functional languages}


Typing judgments are of the form $[[ G |- t : A ]]$, where $[[ G ]]$ ranges over
contexts of assumptions:
\begin{equation*}
  [[ G ]] ::= \emptyset
  \mid [[ G , x : A ]]
\tag{contexts}
\end{equation*}

Thus, a context may be empty $\emptyset$, or extended with a linear assumption $[[
x : A ]]$. Throughout, comma denotes disjoint context concatenation as well as 
context extension. We treat contexts as unordered lists, thus making the exchange 
rule admissible. 

The syntax of terms is the same as STLC, given by:
\begin{align*}
  [[ t ]] ::= \;
         & [[ x ]]
    \mid [[ \x . t ]]
    \mid [[ t1 t2 ]]
  {\small{\tag{terms}}}
\end{align*}
That is, a term is either a linear variable usage $x$, an abstraction which binds a
linear variable $x$ in the term $t$, or an application of the argument $t_1$ to $t_2$. 

\begin{figure}[t]
\begin{gather*}
    \begin{array}{c}
\inferrule*[right = Var]
  {\;}
  {[[ x : A |- x : A ]]}
\\[1.25em]
\inferrule*[right = Abs]
{[[ G , x : A |- t : B ]]}
{[[ G |- \x . t : A -o B ]]}
\;\;\;\;
% \\[0.75em]
\inferrule*[right = App]
{[[ G1 |- t1 : A -o B ]] \;\;\;
 [[ G2 |- t2 : A ]] }
{[[ G1 + G2 |- t1 t2 : B ]]}
\end{array}
\end{gather*}
\caption{Typing rules for the linear $\lambda$-calculus}
\label{fig:lin-lambda-calc}
\end{figure}
Figure~\ref{fig:lin-lambda-calc} relates the terms to their types via typing
rules. Linear variables are typed in a singleton context (\textsc{Var}).
Abstraction (\textsc{Abs}) binds a linear variable which is used to type the
premise. Application (\textsc{App}) combines the usages across both premises
through the use of \textit{context addition}~\eqref{def:contextAdd}. Context
addition provides an analogue to contraction, combining contexts that have come
from typing multiple sub-terms in a rule. Context addition, written $[[ G1 +
G2]]$, is undefined if $[[ G1 ]]$ and $[[ G2 ]]$ overlap in their assumptions,
i.e. a linear assumption may not appear in both sides of the addition. This is 
equivalent to concatenation on disjoint contexts.
\begin{definition}[Linear context addition]\label{def:contextAddLin}
  \begin{align*}
      \setlength{\arraycolsep}{0.1em}
      \begin{array}{rl}
        [[ G + . ]] & = [[ G ]] \\ 
        [[ . + G ]] & = [[ G ]] \\
      [[ (G, x : A) + G' ]] & = [[ (G + G'), x : A ]] \quad \text{iff} \,\; x
      \not\in | [[ G' ]] | \\
      [[ G + (G', x : A) ]] & = [[ (G + G'), x : A ]] \quad \text{iff} \,\; x \not\in | [[ G]] | 
      \end{array}
  \end{align*}
\end{definition}

This leaves us with a very simple resourceful typing calculus, which serves as
the building block for further refinement.

\begin{example}
  \label{example:linear-granule}
An example of a program typeable in this calculus is the combinator for function
composition: 
\begin{align*}
\begin{array}{ll}
    comp: (A \multimap B) \multimap (B \multimap C) \multimap A \multimap C &
    \\
    comp = \lambda x. \lambda y. \lambda z. y\ (x\ z) &
\end{array}  
\end{align*}
Here, each argument is used exactly once in body of the innermost lambda, satisfying 
linearity. In Granule code, the above program may be written as:
\begin{granule}
comp : forall { a b c : Type } . (a -> b) -> (b -> c) -> a -> c
comp x y z = y (x z)
\end{granule}
Note that Granule code uses $\rightarrow$ syntax rather than $\multimap$ for
linear functions for the sake of familiarity with standard functional languages.
Granule features ML style polymorphism, thus top level definitions are annotated
with type schemes which quantify over kind-annotated type variables.
% Granule has ML style polymorphism (Rank-1 polymorphism), thus we quantify over 

In contrast, the \emph{K} combinator from SKI combinatory logic is not typeable in the 
linear $\lambda$-calculus:
\label{k-example}
\begin{align*}
  \tag{ill-typed}
\begin{array}{ll}
    k : A \multimap B \multimap A &
    \\
    k = \lambda x. \lambda y. x &
\end{array}  
\end{align*}
as $y$ is discarded in the body of the abstraction, violating linearity. Again, 
in Granule we could try to write this program as:
\begin{granule}
k : forall { a b : Type } . a -> b -> a
k x y = x             -- ill-typed
\end{granule}
However, this will fail to type check, due to the aforementioned violation of
linearity.
\end{example}

\section{From Linearity to Grades}
\label{sec:graded-linear}
Now that we have seen the linear $\lambda$-calculus itself, we are ready to
generalise the notion of data as a resource inside a program, and formally
define a graded type system. We now present two calculi, each based on the
differing view of graded types mentioned at the top of this chapter. The first
directly follows from the calculus in~\ref{sec:linear-lambda-calc}, merely
extending it with a \emph{graded modal type}. The second reflects the other
approach to graded type systems where instead of the underlying linear
structure, grades are introduced via the function type because all assumptions
carry a grade.

\subsection{The Graded Linear $\lambda$-calculus}
\label{sec:linear-base}
We now define a core type system, based on the linear $\lambda$-calculus of
section~\ref{sec:linear-lambda-calc}, extended with a graded modal type. This
calculus is equivalent to the core calculus of Granule,
\textsc{GrMini}~\citep{DBLP:journals/pacmpl/OrchardLE19}, as well as the calculi
of~\citet{DBLP:conf/esop/BrunelGMZ14},~\citet{DBLP:conf/esop/GhicaS14},~\citet{coeffects-thesis},~\citet{petricek2014coeffects},
and ~\citet{DBLP:conf/icfp/GaboardiKOBU16} (minus graded monads). Similar
approaches have been used in more specialised systems such as the linear
dependent type system of~\citet{Lago_2012}, and the work
of~\citet{gaboardi2013linear}, which uses grades to capture and enforce
properties of differential privacy.

We refer to the system in this section as the \textit{graded
linear $\lambda$-calculus}, reflecting the underlying linear structure of the
system.

Given a typing judgment $[[ G |- t : A ]]$ we say that $t$ is both
\emph{well-typed} and \emph{well-resourced} to highlight the role of grading in
accounting for resource use via the semiring information.

This system forms the basis of the target language for our synthesis tool in
Chapter~\ref{chapter:core}, although we extend it with some basic types for 
increased expressivity.


The types of the graded linear $\lambda$-calculus are given by:
\begin{align*}
[[ A ]] , [[ B ]] & ::=
       [[ A ]] \multimap [[ B ]]
  \mid [[ [] r A ]]
{\small{\tag{types}}}
\end{align*}
where the type $\Box_{r} A$ is an indexed family of type operators where $r$ is
a \textit{grade} ranging over the elements of a pre-ordered semiring
$({\mathcal{R}}, \cdot, {1}, {+}, {0}, {\sqsubseteq})$ parametrising the
calculus (where $\cdot$ and $+$ are monotonic operations (which may be partial)
with respect to the pre-order $\sqsubseteq$). 

From this semiring structure, we can derive two partial operations on grades which will
be useful later on: \emph{greatest lower bounds} ($\sqcap$), and \emph{least
upper bounds} ($\sqcup$). These are given by Definitions~\ref{def:glb} and~\ref{def:def-lub},
respectively.

\begin{definition}[Partial greatest-lower bound of grades]
  \label{def:glb}
  For two grades $r$ and $s$ of a given semiring, $r \sqcap s$ is defined in
  terms of the semiring's preorder: $r \sqcap s = t$ if $t \sqsubseteq r$ and $ 
  t \sqsubseteq s$ and there exists no other $t'$ where $t' \sqsubseteq r$,  
  $t' \sqsubseteq s$ and $ t \sqsubseteq t'$
\end{definition}

\begin{definition}[Partial least-upper bound of grades]
  \label{def:def-lub}
  For two grades $r$ and $s$ of a given semiring, $r \sqcup s$ is defined in
  terms of the semiring's preorder: $r \sqcup s = t$ if $r \sqsubseteq t$ and $ 
  s \sqsubseteq t$ and there exists no other $t'$ where $r \sqsubseteq t'$, 
  $s \sqsubseteq t'$ and $t' \sqsubseteq t$
\end{definition}

As before, typing judgments are of the form $[[ G |- t : A ]]$, where $[[ G ]]$
ranges over contexts:
\begin{equation*}
  [[ G ]] ::= \emptyset
  \mid [[ G , x : A ]]
  \mid [[ G , x : [ A ] r ]]
\tag{contexts}
\end{equation*}
Thus, a context may also be extended with a graded assumption $[[x : [A] r]]$.
For linear assumptions, structural rules of weakening and contraction are
disallowed. Graded assumptions may be used non-linearly according to the
constraints provided by their grade, the semiring element $r$. 

Various operations on contexts are used to capture non-linear data flow via
grading. As with the linear $\lambda$-calculus, context
addition~\eqref{def:contextAdd} combines the contexts used to provide multiple
sub-terms. However, our new definition includes an extra case for dealing with
graded assumptions appearing in both contexts, which are combined
via the semiring $+$ of their grades. Note that this is again a partial definition
where addition may be undefined.

\begin{definition}[Graded linear context addition]\label{def:contextAdd}

\begin{gather*}
    \setlength{\arraycolsep}{0.1em}
    \begin{array}{rl}
        [[ G + . ]] & = [[ G ]] \\ 
        [[ . + G ]] & = [[ G ]] \\
    [[ (G, x : A) + G' ]] & = [[ (G + G'), x : A ]] \quad \text{iff} \,\; x
    \not\in | [[ G' ]] | \\
    [[ G + (G', x : A) ]] & = [[ (G + G'), x : A ]] \quad \text{iff} \,\; x \not\in | [[ G]] | \\
    [[ (G, x : [ A ] r) + G' ]] &= [[ (G + G'), x : [A ] r ]] \quad \text{iff} \,\; x \not\in | [[ G']] | \\
    [[ G + (G', x : [ A ] r) ]]  &= [[ (G + G'), x : [ A ] r ]] \quad \text{iff} \,\; x \not\in | [[ G]] | \\
    [[ (G, x : [ A ] r) + (G', x : [ A ] s) ]] & = [[ (G + G'), x : [ A ] (r + s) ]]
    \end{array}
  \end{gather*}

Note that this is a declarative specification of context addition. Graded
assumptions may appear in any position in $\Gamma$ and $\Gamma'$ as witnessed by
the algorithmic specification where for all $[[ G1 ]], [[ G2 ]]$ context
addition is defined as follows by ordered cases matching inductively on the
structure of $[[ G2 ]]$, where $[[G1 + G2]] = $
\begin{align*}
\left\{\begin{matrix}
    \begin{array}{ll}
    [[G1]] &
     [[G2]] = \emptyset \\
     ([[ G1 ]] + [[ G2' ]]), [[ x : [ A ] r ]]  & [[ G2 ]] = [[ G2', x : [ A ] r ]]\ \wedge\ [[ x : [A] r ]] \notin [[ G1 ]] \\ 
      (([[G1']], [[G1'']]) + [[G2']]), [[x : [A] (r + s)]] \; &
[[ G2]] = [[G2', x : [A] s]] \wedge [[G1]] = [[ G1',x : [A] r]],[[G1'']]  \\
 ([[G1]] + [[G2']]), [[x : A]] & [[G2]] = [[G2', x : A]]\ \wedge\  [[x
                                  : A]] \notin [[ G1 ]]
    \end{array}
  \end{matrix}\right.
\end{align*}
\end{definition}
For example, the context addition of $x :_4 A, y :_3 B$ and $x :_2 A, y :_5 B$
would yield a context $x :_6 A, y :_8 B$ (using the definition of $+$ from the
natural numbers semiring). However, the context addition of $x : A, y :_2 B$ and
$x : A, y :_3 B$ is undefined, as the linear assumption $x$ is present in both
sides of the addition.

The terms of the language are given by:
\begin{align*}
[[ t ]] ::= \;
       & [[ x ]]
  \mid [[ \x . t ]]
  \mid [[ t1 t2 ]]
  \mid [[ [t] ]]
  \mid [[ let [ x ] = t1 in t2 ]]
{\small{\tag{terms}}}
\end{align*}
In addition to the the terms of the linear $\lambda$-calculus, we also have the
construct $[[ [t] ]]$ which introduces a graded modal type $[[ [] r A
]]$ by `promoting' a term $t$ to the graded modality, and it's dual $[[ let [x] = t1
in t2 ]]$ eliminates a graded modal value $[[ t1 ]]$, binding a graded variable $x$
in scope of $[[ t2 ]]$. The typing rules relate these terms to types.


\begin{figure}[t]
\hspace{-0.5em}
\begin{align*}
\hspace{-0.5em}
  \begin{array}{c}
  \inferrule*[right = Var]
  {\;}
  {[[ x : A |- x : A ]]}
\;\;
  \inferrule*[right = Abs]
  {[[ G , x : A |- t : B ]]}
  {[[ G |- \x . t : A -o B ]]}
\\[1.25em]
  \inferrule*[right = App]
  {[[ G1 |- t1 : A -o B ]] \;\;\;
   [[ G2 |- t2 : A ]] }
  {[[ G1 + G2 |- t1 t2 : B ]]}
\\[1.25em]
 \inferrule*[right = Weak]
  {[[ G |- t : A ]]}
  {[[ G , {[ D , 0 ]} |- t : A ]]}
\;\;\;
\inferrule*[right = Der]
  {[[ G , x : A |- t : B ]]}
  {[[ G , x : [ A ] 1 |- t : B]]}
\\[1.25em]
\inferrule*[right = Approx]
{[[ {G, x : [A] r}, G' |- t : A ]] \quad r \sqsubseteq s }
{[[ {G, x : [A] s}, G' |- t : A ]]}
\\[1.25em]
\inferrule*[right = Pr]
  {[[ [ G ] |- t : A ]]}
  {[[ r * {[ G ]} |- [t] : [] r A ]]}
\;\;\;
\inferrule*[right = Let$\Box$]
  {[[ G1 |- t1 : [] r A ]] \;\;\;
   [[ G2, x : [ A ] r |- t2 : B ]] }
    {[[ G1 + G2 |- let [x] = t1 in t2 : B ]]}
\end{array}
\end{align*}
\vspace{-1.25em}
  \caption{Typing rules of the graded linear $\lambda$-calculus}
\label{fig:typing}
 \end{figure}


Figure~\ref{fig:typing} gives the typing rules. The $\textsc{Weak}$ rule
captures weakening of assumptions graded by $0$, where $[[ [ D , 0 ] ]]$ denotes
a context containing only graded assumptions graded by $0$, a predicate on
contexts given by Definition~\ref{def:zeroedContexts}: 
\begin{definition}[Zeroed graded contexts]
  \label{def:zeroedContexts}
  For all contexts $[[ G ]]$, $ [[ [ G, 0 ] ]]$ is defined:
\begin{align*} 
  % \begin{array}{c}
    % \hspace{-0.9em}
    [ \emptyset ]_0 = \emptyset
    \qquad & \qquad
    [[ [ {G, x : [A] 0} ] ]]_0 = [[ [ G, 0 ] ]], [[ {x : [ A ] 0} ]] 
    % \\
    \\
    [[ [ {G, x : [A] r} ] ]]_0 =\ \perp 
    % \\
    \qquad & \qquad
   [[ [ G, x : A ] ]]_0 =\ \perp
  % \end{array}
\end{align*}
\end{definition}

Context addition and \textsc{Weak} together therefore provide the rules of
substructural rules of contraction and weakening for graded variables.
Dereliction ($\textsc{Der}$), allows a linear assumption to be converted to a
graded assumption with grade $1$. 

We allow grade \textit{approximation} via their resource algebras through the
application of the $\textsc{Approx}$ rule. A grade $s$ may be converted to
another grade $r$, providing that $r$ iw \textit{approximated} by $s$, where the
relation $\sqsubseteq$ is the pre-order provided with the semiring. This
relation is occasionally lifted pointwise to contexts, ignoring linear
assumptions: we write $[[ G <<= G' ]]$ to mean that $[[ G' ]]$ overapproximates
$[[ G ]]$ meaning that for all $[[ (x : [A] r) ]] \in [[ G ]]$ then $[[ (x : [A]
r') ]] \in [[ G' ]]$ and $[[ r <<= r' ]]$. 

Introduction and elimination of the graded modality is provided by the
$\textsc{Pr}$ and $\textsc{Let}$ rules respectively. The $\textsc{Pr}$ rule
propagates the grade $r$ to the assumptions through \emph{scalar multiplication}
of $[[G]]$ by $r$ where every assumption in $[[ G ]]$ must already be graded.
Definition~\ref{def:gradedContext} defines a predicate on $[[ G ]]$ in the form
of a partial operation which ensures that $[[ G ]]$ contain only graded
variables (written $[[ [ G ] ]]$):
\begin{definition}[Solely graded contexts]
  \label{def:gradedContext}
For all contexts $[[ G ]]$, $ [[ [G] ]]$ is defined:
\begin{align*}
    [ \emptyset ] = \emptyset
    \qquad\qquad
    [[ [ G, x : [A] r ]  ]] = [[ [ G ] ]], [[ x : [ A ] r ]]
    \qquad\qquad
   [[ [ G, x : A ] ]] =\ \perp
\end{align*}
When an assumption in $[[ [G] ]]$ is graded, the identity is returned, otherwise 
(i.e. if an assumption is linear) the operation is undefined.
\end{definition}
Scalar multiplication is then given by:
Definition~\ref{def:scalar}.
%
%
\begin{definition}[Scalar context multiplication]
  \label{def:scalar}
 A context which consists solely of graded assumptions, i.e. $[[ [G] ]]$, can be
 multiplied by a semiring grade $r \in \mathcal{R}$
\begin{align*}
   [[ r * . ]] = \emptyset
    \qquad\qquad
    [[ r * (G , x : [ A ] s) ]] = [[ (r * G), x : [ A ] (r * s) ]]
\end{align*}
\end{definition}

The $\textsc{Let}$ rule eliminates a graded modal value $[[ [] r A ]]$
into a graded assumption $[[ x : [ A ] r ]]$ with a matching
grade in the scope of the \textbf{let} body. This is also referred to as
``unboxing''.

We give an example of graded modalities using a graded modality indexed
by the semiring of natural numbers.

%SKI
\begin{example}
\label{ex:s-comb}
  The natural number semiring with discrete ordering $(\mathbb{N}, \cdot, 1, +,
  0, \equiv)$ provides a graded modality that counts exactly how many times
  non-linear values are used. As an example, the \emph{S} combinator from
  the SKI system of combinatory logic is typed and defined:
% then2 : forall {a b c : Type} . (a -> (b -> c)) -> (a -> b) -> (a
% [2] -> c)
\begin{align*}
s & : [[ (A -o (B -o C)) -o {(A -o B) -o ({[] 2 A} -o C)} ]] \\
s & = [[ \x . {\y . {\z' . {let [ z ] = z' in {(x z) (y z)}}}} ]]
\end{align*}
The graded modal value $z'$ captures the capability for a value
of type $A$ to be used twice. This capability is made available by eliminating
$\Box$ (via \textbf{let}) to the variable $z$, which has
grade $2$ in the scope of the body. 
The Granule code equivalent of this program is:
\begin{granule}
s : forall { a b c : Type } 
  . (a -> (b -> c)) -> (a -> b) -> (a [2] -> c)
s x y z' = let [z] = z' in (x z) (y z)
\end{granule}
Likewise, we can now correctly type and write the \emph{K} combinator from
Section~\ref{sec:linear-lambda-calc} as:
\begin{align*}
k & : [[ {A -o [] 0 B} -o A ]] \\
k & = [[ \x . \ y' . {let [ y ] = y' in x }]]
\end{align*}
with the equivalent Granule code:
\begin{granule}
k : forall { a b : Type } . a -> b [0] -> a
k x y' = let [y] = y' in x
\end{granule}
Granule also includes pattern matching (which we extend our calculi with in
Chapter~\ref{chapter:deriving}), allowing us to refactor the above two programs
to pattern match on the graded modalities in the function equations:
\begin{granule}
s : forall { a b c : Type } 
  . (a -> (b -> c)) -> (a -> b) -> (a [2] -> c)
s x y [z] = (x z) (y z)

k : forall { a b : Type } . a -> b [0] -> a
k x [y] = x
\end{granule}


\end{example}
\begin{example}
\label{example:graded-granule}
While our calculus in Figure~\ref{fig:typing} is parametrised by a semiring
making grades monomorphic, in Granule code we may be explicitly polymorphic in
the grades used by quantifying over the semiring. For example, we can then write
a graded version of \granin{comp} from Section~\ref{sec:linear-lambda-calc}
(i.e. coKleisli composition) as: 
\begin{align*}
\textit{comp-}\textit{coK}_{\mathcal{R}} & : \Box_r (\Box_s A \multimap B) \multimap (\Box_r B \multimap C) \multimap \Box_{r \cdot s} A \multimap C \\
\textit{comp-}\textit{coK}_{\mathcal{R}} & = \lambda x . \lambda y . \lambda z . \textbf{let}[u] = x\ \textbf{in}\ \textbf{let}[v] = z\ \textbf{in}\ y\ [u\ [ v ] ]
\end{align*}
which we can write as a Granule program which is polymorphic with respect to
grades as well as types:
\begin{granule}
compCoK : forall {k : Semiring, r s : k, a b c : Type} 
     . (a [s] -> b) [r] 
     -> (b [r] -> c) 
     -> a [r * s] 
     -> c
compCoK x y z = let [u] = x in let [v] = z in y  [ u [v] ]
\end{granule}
The type scheme for \granin{compCoK} quantifies over the semiring \granin{k},
and then grade variables \granin{r} and \granin{s} with the kind \granin{k}. The
grades must then be used in the type in a polymorphic way.
% The corresponding type derivation for 
% this term is:
% \begin{align*}
%   \inferrule*[]
%     {}
%     {}
% \end{align*}
\end{example}

\begin{example}

  \label{example:01omega}
    The $!$ modality can be (almost) recovered via the \{$\mathsf{Zero}$,\
    $\mathsf{One}$,\ $\omega$\} semiring. For this semiring, we define $+$ as $r
    + s = r$ if $s = \mathsf{Zero}$, $r + s = s$ if $r = \mathsf{Zero}$,
    otherwise $\omega$. Multiplication is $r \cdot \mathsf{Zero} = \mathsf{Zero}
    \cdot r = \mathsf{Zero}$, $r \cdot \omega = \omega \cdot r = \omega$ (where
    $r \neq \mathsf{Zero}$), and $r \cdot 1 = 1 \cdot r = r$. Ordering is
    defined as $\mathsf{Zero} \sqsubseteq \omega$ and $\mathsf{One} \sqsubseteq
    \omega$. This semiring allows us to express both linear and non-linear usage
    of values, with a $\mathsf{One}$ grade indicating linear use,
    $\mathsf{Zero}$ requires the value be discarded, and $\omega$ acting as
    linear logic's ! and permitting unrestrained use. This is similar to Linear
    Haskell's multiplicity annotations (although Linear Haskell has no
    equivalent of a $\mathsf{Zero}$ grade, only having $\mathsf{One}$ and
    $\mathsf{Many}$ annotations)~\citep{DBLP:journals/pacmpl/BernardyBNJS18}.
    Using this semiring, we can write the \emph{K} combinator from
    Example~\ref{ex:s-comb} above in Granule as:
    \begin{granule}
k : forall { a b : Type } . a [One] -> b [Zero] -> a
k x' y' = let [x] = x' in let [y] = y' in x
      \end{granule}
  Note however that some additional restrictions are required on typing to get
  exactly the behaviour of $!$ with respect to
  products~\citep{hughes:lirmm-03271465}. This is an orthogonal discussion and
  not relevant to the rest of this work.
  \end{example}

\subsection{The Fully Graded $\lambda$-calculus}
\label{sec:graded-base}
As mentioned before, the second style of graded cacluli that we consider are
\emph{fully graded} systems, such as those used in practical systems today. For
example, this is the approach taken by Idris
2~\citep{DBLP:journals/corr/abs-2104-00480} and the linear types extension to
Haskell~\citep{DBLP:journals/pacmpl/BernardyBNJS18}.

We now define a core calculus for such a type system, where grades permeate the
entire program, drawing from the coeffect calculus of
\citet{petricek2014coeffects}, Quantitative Type Theory (QTT) by
\citet{McBride2016} and refined further by \citet{quantitative-type-theory}, the calculus of
\citet{DBLP:journals/pacmpl/AbelB20}, and other graded dependent type theories,
such as~\citet{DBLP:conf/esop/MoonEO21} (although we omit dependent types from our language). We refer to this system as the
\textit{fully graded $\lambda$-calculus}.

The syntax of types is given by:
\begin{align*}
[[ A ]] , [[ B ]] & ::=
       [[ A ^ r -> B ]]
  \mid [[ [] r A ]]
{\small{\tag{\textit{types}}}}
\end{align*}
where the function arrow $[[ A ^ r -> B ]]$ annotates the input type with a
\emph{grade} $[[ r ]]$ which is again drawn from a pre-ordered semiring
$(\mathcal{R}, {\cdot}, {1}, {+}, {0}, \sqsubseteq)$ parametrising the calculus.
The graded necessity modality $[[ [] r A ]]$ is similarly annotated by the grade
$[[ r ]]$ being an element of the semiring. 

Typing judgements have
the same form as Section~\ref{sec:linear-base}, however, variable contexts are
instead given by: 
\begin{equation*}
  [[ D ]], [[ G ]] ::= \emptyset
  \mid [[ G , x : [ A ] r ]]
\tag{\textit{contexts}}
\end{equation*}
That is, a context may be empty $\emptyset$ or extended with a \textit{graded}
assumption $ [[ x : [A] r ]]$, which must be used in a way which adheres to the
constraints of the grade $[[ r ]]$. Note that we no longer include linear
assumptions as part of our contexts. As before, structural exchange is
permitted, allowing a context to be arbitrarily reordered. 

The syntax of terms is given as:
%
\begin{align*}
[[ t ]] ::= \;
       & [[ x ]]
  \mid [[ \x ^ c . t ]]
  \mid [[ t1 t2 ]]
  \mid [[ [t] ]]
  \mid [[ let [ x ] = t1 in t2 ]] 
  % \mid [[ case t of p1 -> t1 ; * ; pn -> tn  ]]
{\small{\tag{\textit{terms} }}}
\end{align*}
%
As before, terms comprise the $\lambda$-calculus, extended with the \textit{promotion}
construct [t] as seen in Section~\ref{sec:linear-base}. 

\begin{figure}[t]
\hspace{-0.5em}
\begin{align*}
\hspace{-0.5em}
\begin{array}{c}
\GRANULEdruleTyVar{}
\;\;\;
\GRANULEdruleTyAbs{}
\\[1.25em]
\GRANULEdruleTyApp{}
\\[1.25em]
\GRANULEdruleTyApprox{}
\;\;\;
\GRANULEdruleTyPr{}
\\[1.25em]
\inferrule*[right = Let$\Box$]
  {[[ G1 |- t1 : [] r A ]] \;\;\;
   [[ G2, x : [ A ] r |- t2 : B ]] }
    {[[ G1 + G2 |- let [x] = t1 in t2 : B ]]}
\end{array}
\end{align*}
\vspace{-0.5em}
\caption{Typing rules for the fully graded $\lambda$-calculus}
\label{fig:graded-typing}
\vspace{-0.5em}
 \end{figure}

Figure~\ref{fig:graded-typing} gives the full typing rules, which explains the meaning of
the syntax with reference to their static semantics.

Variables (rule \textsc{Var}) are typed in a context where the variable $x$ has
grade $1$ denoting its single usage here. All other variable assumptions are
given the grade of the $0$ semiring element (providing weakening), using
\textit{scalar multiplication} of contexts by a grade, re-using
Definition~\ref{def:scalar} from Section~\ref{sec:linear-base}.

Abstraction (\textsc{Abs}) captures the assumption's grade $[[ r ]]$ onto the
function arrow in the conclusion, that is, abstraction binds a variable $[[x]]$
which may be used in the body $[[t]]$ according to grade $[[ r ]]$. Application
again (\textsc{App}) makes use of context addition to combine the contexts used to
type the two sub-terms in the premises of the application rule:

% \begin{definition}[Graded context addition]\label{def:contextAddGraded}
% For all $[[ G1 ]], [[ G2 ]]$ \emph{graded context addition} is defined
% as follows by ordered cases matching inductively on the structure of
% $[[ G2 ]]$, where $[[G1 + G2]] = $
% \begin{gather*}
% \left\{\begin{matrix}
%     \begin{array}{ll}
%     [[G1]] &
%     [[G2]] = \emptyset
%              \\
%       (([[G1']], [[G1'']]) + [[G2']]), [[x : [A] (r + s)]] \; &
% [[ G2]] = [[ G2', x : [A] s]] \wedge [[G1]] = [[ G1',x : [A] r]],[[G1'']] \\
%  [[ (G1 + G2'), x : [A] s ]] & [[ G2 ]] = [[ G2' , x : [A] s ]] \wedge [[ x ]] \not\in \mathsf{dom}([[ G1 ]])
% \end{array}
%   \end{matrix}\right.
% \end{gather*}
% \end{definition}

\begin{definition}[Graded context addition]\label{def:contextAddGraded}

\begin{gather*}
    \setlength{\arraycolsep}{0.1em}
    \begin{array}{rl}
        [[ G + . ]] & = [[ G ]] \\ 
        [[ . + G ]] & = [[ G ]] \\
    [[ (G, x : [ A ] r) + G' ]] &= [[ (G + G'), x : [A ] r ]] \quad \text{iff} \,\; x \not\in | [[ G']] | \\
    [[ G + (G', x : [ A ] r) ]]  &= [[ (G + G'), x : [ A ] r ]] \quad \text{iff} \,\; x \not\in | [[ G]] | \\
    [[ (G, x : [ A ] r) + (G', x : [ A ] s) ]] & = [[ (G + G'), x : [ A ] (r + s) ]]
    \end{array}
  \end{gather*}

As in the linear graded case, we also provide the algorithmic definition of
graded context addition, where graded assumptions may appear in any position in
$\Gamma$ and $\Gamma'$ as witnessed by the algorithmic specification where for
all $[[ G1 ]], [[ G2 ]]$ context addition is defined as follows by ordered cases
matching inductively on the structure of $[[ G2 ]]$, where $[[G1 + G2]] = $
\begin{align*}
\left\{\begin{matrix}
    \begin{array}{ll}
    [[G1]] &
     [[G2]] = \emptyset \\
     ([[ G1 ]] + [[ G2' ]]), [[ x : [ A ] r ]]  & [[ G2 ]] = [[ G2', x : [ A ] r ]]\ \wedge\ [[ x : [A] r ]] \notin [[ G1 ]] \\ 
      (([[G1']], [[G1'']]) + [[G2']]), [[x : [A] (r + s)]] \; &
[[ G2]] = [[G2', x : [A] s]] \wedge [[G1]] = [[ G1',x : [A] r]],[[G1'']]      
\end{array}
  \end{matrix}\right.
\end{align*}
\end{definition}

Note that Definition~\ref{def:contextAddGraded} differs only from~\ref{def:contextAdd}, in
that the former need not consider linear assumptions.

As an example of the \textsc{App} rule, consider the following typing derivation for 
a program of type $(A^3 \rightarrow B)^1 \rightarrow A^3 \rightarrow B$: 
\begin{align*}
  \inferrule*[right=\textsc{Abs}]{
  \inferrule*[right=\textsc{Abs}]{
  \inferrule*[right=\textsc{App}]
    {\inferrule*[right=\textsc{Var}]
      {\quad}
      {x :_1 A^3 \rightarrow B \vdash x : A^3 \rightarrow B} \\ 
    \inferrule*[right=\textsc{Var}, rightskip=3em]
      {\quad}
      {y :_1 A \vdash y : A}}
    { x :_1 A^3 \rightarrow B + 3 \cdot y :_1 : A  \rightarrow B \vdash x\ y : B }
  }
  {x :_1 A^3 \rightarrow B \vdash \lambda y . x\ y : A^3 \rightarrow B}}
  {\emptyset \vdash \lambda x . \lambda y . x\ y : (A^3 \rightarrow B)^1 \rightarrow A^3 \rightarrow B }
\end{align*}
This program binds a function $x$ of type $A^3 \rightarrow B$ with grade 1, i.e.
it consumes its input according to a grade of 3 and the function itself can be
used once. The application of $y$ to $x$ satisfied this grade usage, as $y$ has
a grade of $3$. In the \textsc{App} rule, we type a single use of $y$ in the
second premise via the \textsc{Var} rule, and then scale this usage by the grade
3 on the function arrow of $x$, satisfying the grade $y$ was bound with in the
\textsc{Abs} rule.


Explicit introduction of graded modalities is achieved via the rule for
promotion (\textsc{Pr}). This rule is almost identical to that
of~\ref{sec:linear-base} with the only difference being here $[[ G ]]$ is known
to always contain only graded assumptions, so the predicate $[[ [G] ]]$ is not
needed. Explicit unboxing (\textsc{Let$\Box$}), and approximation
(\textsc{Approx}) are likewise identical to the calculus
of~\ref{sec:linear-base}.   

\begin{example}
We now consider the Granule programs shown in
Examples~\ref{example:linear-granule},~\ref{ex:s-comb} (pages~\pageref{example:linear-granule},~\pageref{k-example}), 
and~\ref{example:graded-granule} (page~\pageref{example:graded-granule}) but written instead in this fully graded style.
The combinator for linear function composition is written: 
\begin{align*}
comp & : (A^1 \rightarrow B)^1 \rightarrow (B^1 \rightarrow C)^1 \rightarrow A^1 \rightarrow C \\
comp & = \lambda x . \lambda y . \lambda z = y\ (x\ z)
\end{align*}
and in Granule as: 
\begin{granule}
language GradedBase 

comp : forall { a b c : Type } . (a %1 -> b) %1 -> (b %1 -> c) %1 -> a %1 -> c
comp x y z = y (x z)
\end{granule}
To do so, we enable the \granin{GradedBase} language extension in Granule.
Grades are written on function arrows using \granin{\%} (in the same way that
\emph{multiplicity} annotations are written in Linear Haskell). We elide this
enabling of the language extension in code examples henceforth. Omitting a grade
annotation defaults to a grade of $1$. So this function may also be written
without any annotations with the same meaning. Note that at the term level, we
do not need to unbox values graded by a function arrow to use them in according
to their grades. However, we may make explicit use of graded modalities which
does necessitate unboxing. Thus, the graded coKleisli version of function
composition from Example~\ref{example:graded-granule} can be written as:  
\begin{align*}
\textit{comp-}\textit{coK}_{\mathcal{R}} & : \Box_r (A^s \rightarrow B)^r \rightarrow (B^r \rightarrow C)^1 \rightarrow \Box_{r \cdot s} A \rightarrow C \\
\textit{comp-}\textit{coK}_{\mathcal{R}} & = \lambda x . \lambda y . \lambda z . \textbf{let}[v] = z\ \textbf{in}\ y\ [x\ [ v ] ]
\end{align*}
with the equivalent Granule code: 
\begin{granule}
compCoK : forall {k : Semiring, r s : k, a b c : Type} 
     . (a %s -> b) %r
     -> (b %r -> c) 
     -> a [r * s] 
     -> c
compCoK x y z = let [v] = z in y  [ u [v] ]
\end{granule}
leveraging the fact that omitting a grade annotation in the type yields a $1$
grade. Likewise, \emph{S} and \emph{K} can be typed and written as: 
\begin{align*}
s & : (A^1 \rightarrow (B^1 \rightarrow C))^1 \rightarrow (A^1 \rightarrow B)^1 \rightarrow (A^2 \rightarrow C) \\
s & = \lambda x . \lambda y . \lambda z . (x\ z)\ (y\ z)\\
\\
k & : A^1 \rightarrow B^0 \rightarrow A \\
k & = \lambda x . \lambda y . x 
\end{align*}
with Granule equivalents:
\begin{granule}
s : forall { a b c : Type } 
  . (a -> (b -> c)) -> (a -> b) -> (a %2 -> c)
s x y z = (x z) (y z)

k : forall { a b : Type } . a -> b %0 -> a
k x y = x 
\end{granule}
\end{example}

\section{Operational Semantics}
\label{sec:op-sem}
We briefly present the reduction rules for a call-by-name operational semantics
for our calculi~\citep{tale-of-two-calculi}. The Granule interpreter also provides a
call-by-value semantics which can be enabled via a language extension. Note that
the rules are identical for both the graded linear and fully graded systems!
Figure~\ref{fig:opsem} collects the rules.
\begin{figure}[H]
% \hspace{-0.5em}
\begin{align*}
\hspace{1.5em}
\begin{array}{c}
\opsemBeta{}
\;\;\;
\opsemApp{}
\\[1.25em]
\opsemBoxBeta{}
\\[1.25em]
\opsemLet{}
\end{array}
\end{align*}
\vspace{-0.5em}
\caption{Reduction rules for the linear graded and fully graded $\lambda$-calculi}
\label{fig:opsem}
\vspace{-0.5em}
 \end{figure}
 The rules are fairly straightforward and we do not rely on them heavily in
 subsequent chapters, instead providing them for completeness and to give an
 intuition of the dynamic behaviour of our calculi. 

\paragraph{Admissibility of Substitution}
\label{ref:substitution}
Lastly, we remark that substitution is admissible in each of the calculi. Rather
than provide the details at this point, we present the lemmas for
both of the calculi once we have extended them with the additional types
mentioned above in their respective chapters.

\section{Two Typing Calculi}
\label{sec:two-typing}
Having outlined the two lineages of graded type systems, we are left with the
question: what approach should we use as the basis of a target language for a
program synthesis tool? Both systems embed properties for reasoning about
program structure into the language, however, they differ in how this
information is expressed, as shown by the variance in typing and syntax between
Sections~\ref{sec:linear-base} and~\ref{sec:graded-base}. 

Rather than focus entirely on one approach, we opt to instead build synthesis
tools which target both systems. Our approach to synthesis is rooted in the
techniques for resource management in automated theorem proving for linear
logic~\citep{HODAS1994327, CERVESATO2000133}. Therefore,
Chapter~\ref{chapter:core} uses the graded linear $\lambda$-calculus as a
natural starting point for the design of a synthesis calculus, where we build
upon the existing proof search literature to accommodate graded modal types.
In doing so we also extend graded linear $\lambda$-calculus with some other useful types
to make our language more practical, such as linear multiplicative products
$\otimes$, additive sums $\oplus$, and a $\mathsf{Unit}$ type.

Having established how to handle synthesis in the graded linear setting, in
Chapter~\ref{chapter:extended} we then pivot to a synthesis calculi for a
language derived from the fully graded $\lambda$-calculus, as this is the
approach that is most commonly in use by practical systems
today~\citep{DBLP:journals/corr/abs-2104-00480,
DBLP:journals/pacmpl/BernardyBNJS18}. In doing so, we also extend our fully
graded $\lambda$-calculus with recursive ADTs, recursive function definitions,
and polymorphism. As we have seen, systems based on both approaches are in use
today, and both pose their unique challenges in designing a synthesis tool.
Furthermore, the target programming language Granule of our implementations
includes both approaches.\footnote{As of Granule v0.9.3.0. Available at:
https://github.com/granule-project/granule/releases/tag/v0.9.3.0}

By this point we are in a strong position to tackle the problem of program
synthesis, beginning with a simple introduction to the core issues at the heart
of resourceful program synthesis in the next chapter, using our graded linear
$\lambda$-calculus, extended with some simple types 
